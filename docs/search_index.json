[["index.html", "Rによる比較・予測・因果推論入門 ver0.1 はじめに", " Rによる比較・予測・因果推論入門 ver0.1 川田恵介 2021-05-29 はじめに 本ページでは、定量的な比較、（反実仮想）因果推定、予測分析をRによって行う方法を紹介します。 経済学におけるデータ分析の大部分は、複数の変数間での関係性の理解・利用を目的とします。 ここではある結果変数\\(Y\\)と独立変数（群）\\(X=X_1,...,X_L\\)の関係性に焦点を当てます。 また\\(Y\\)と\\(X\\)がともに観察でき、関心のある母集団からランダムサンプリングされたデータが入手出来ているとします（機械学習における教師付き学習に絞っています）。 より具体的な分析目標は大きく（予測）\\(Y\\)の予測関数の推定、（比較）異なる\\(X\\)間での\\(Y\\)の比較、（因果効果）\\(X\\)の変化が\\(Y\\)に与える因果効果の推定、に大別できます。 ここではそれぞれについて簡単な説明とRのサンプルコードを提供します。 データインポート、整理、可視化を行う関数群を統合的に提供するtidyverseパッケージ (Wickham et al. 2019)の利用を前提にします。 AERパッケージ (Kleiber and Zeileis 2008)に含まれる(the US National Medical Expenditure Survey, NMES1988)を例として使用します。 無料で公開されている有力な参考文献として、以下を推薦します。 機械学習を用いた予測：James et al. (2013) 公開ページ 日本語によるR入門：私たちのR: ベストプラクティスの探究 tidyverseパッケージの利用： 公式ページ "],["intro.html", "Chapter 1 準備", " Chapter 1 準備 オフライン環境の整備 Rのインストール R studioのインストール オンライン環境の整備 R cloudへの登録 "],["データ整備.html", "Chapter 2 データ整備 2.1 新しい変数の作成: mutate (tidyverse) 2.2 変数の限定: select (tidyverse) 2.3 サンプルの除外:filter (tidyverse) 2.4 記述統計表の作成", " Chapter 2 データ整備 AERパッケージに含まれるNMES1988を利用 data(&quot;NMES1988&quot;, package = &quot;AER&quot;) raw &lt;- NMES1988 2.1 新しい変数の作成: mutate (tidyverse) tidyverseパッケージに含まれるdplyrパッケージ(Wickham et al. 2021)は、有用な関数を提供 library(tidyverse) mutate関数の利用 df &lt;- mutate(raw, age_2 = age^2 ) 2.2 変数の限定: select (tidyverse) select関数の利用 df &lt;- select(raw, age, income ) 特定の変数の除外 df &lt;- select(raw, -age, -income ) 2.3 サンプルの除外:filter (tidyverse) filter関数の利用 df &lt;- filter(raw, visits &gt;= 7 ) 2.4 記述統計表の作成 記述統計の作成には多くの有益なパッケージが存在 ここではgtsummary(Sjoberg et al. 2021)を使用 library(gtsummary) select関数で必要な変数(visits, health, medicaid)を抜き出し、insuranceごとに連続変数については中央値、カテゴリ変数については頻度を記述 descriptive &lt;- select(raw, visits, health, medicaid, insurance) tbl_summary(descriptive, by = insurance) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #hhpnnyucyd .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #hhpnnyucyd .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #hhpnnyucyd .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #hhpnnyucyd .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #hhpnnyucyd .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #hhpnnyucyd .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #hhpnnyucyd .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #hhpnnyucyd .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #hhpnnyucyd .gt_column_spanner_outer:first-child { padding-left: 0; } #hhpnnyucyd .gt_column_spanner_outer:last-child { padding-right: 0; } #hhpnnyucyd .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #hhpnnyucyd .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #hhpnnyucyd .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #hhpnnyucyd .gt_from_md > :first-child { margin-top: 0; } #hhpnnyucyd .gt_from_md > :last-child { margin-bottom: 0; } #hhpnnyucyd .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #hhpnnyucyd .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #hhpnnyucyd .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #hhpnnyucyd .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #hhpnnyucyd .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #hhpnnyucyd .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #hhpnnyucyd .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #hhpnnyucyd .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #hhpnnyucyd .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #hhpnnyucyd .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #hhpnnyucyd .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #hhpnnyucyd .gt_sourcenote { font-size: 90%; padding: 4px; } #hhpnnyucyd .gt_left { text-align: left; } #hhpnnyucyd .gt_center { text-align: center; } #hhpnnyucyd .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #hhpnnyucyd .gt_font_normal { font-weight: normal; } #hhpnnyucyd .gt_font_bold { font-weight: bold; } #hhpnnyucyd .gt_font_italic { font-style: italic; } #hhpnnyucyd .gt_super { font-size: 65%; } #hhpnnyucyd .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic no, N = 9851 yes, N = 3,4211 visits 3 (1, 7) 4 (2, 8) health poor 204 (21%) 350 (10%) average 721 (73%) 2,788 (81%) excellent 60 (6.1%) 283 (8.3%) medicaid 341 (35%) 61 (1.8%) 1 Median (IQR); n (%) 連続変数について、平均値と標準偏差を記述 tbl_summary(descriptive, by = insurance, statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #nmjjvjusmd .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nmjjvjusmd .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nmjjvjusmd .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nmjjvjusmd .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #nmjjvjusmd .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nmjjvjusmd .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nmjjvjusmd .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nmjjvjusmd .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nmjjvjusmd .gt_column_spanner_outer:first-child { padding-left: 0; } #nmjjvjusmd .gt_column_spanner_outer:last-child { padding-right: 0; } #nmjjvjusmd .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #nmjjvjusmd .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #nmjjvjusmd .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nmjjvjusmd .gt_from_md > :first-child { margin-top: 0; } #nmjjvjusmd .gt_from_md > :last-child { margin-bottom: 0; } #nmjjvjusmd .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nmjjvjusmd .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #nmjjvjusmd .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nmjjvjusmd .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #nmjjvjusmd .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nmjjvjusmd .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nmjjvjusmd .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nmjjvjusmd .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nmjjvjusmd .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nmjjvjusmd .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #nmjjvjusmd .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nmjjvjusmd .gt_sourcenote { font-size: 90%; padding: 4px; } #nmjjvjusmd .gt_left { text-align: left; } #nmjjvjusmd .gt_center { text-align: center; } #nmjjvjusmd .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nmjjvjusmd .gt_font_normal { font-weight: normal; } #nmjjvjusmd .gt_font_bold { font-weight: bold; } #nmjjvjusmd .gt_font_italic { font-style: italic; } #nmjjvjusmd .gt_super { font-size: 65%; } #nmjjvjusmd .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Characteristic no, N = 9851 yes, N = 3,4211 visits 5 (6) 6 (7) health poor 204 (21%) 350 (10%) average 721 (73%) 2,788 (81%) excellent 60 (6.1%) 283 (8.3%) medicaid 341 (35%) 61 (1.8%) 1 Mean (SD); n (%) "],["可視化.html", "Chapter 3 可視化 3.1 Y=連続、Xカテゴリ 3.2 Y=連続、X=連続", " Chapter 3 可視化 tidyverseに含まれるggplot2パッケージ(Wickham et al. 2020)を利用 library(tidyverse) 引き続きcausaldataに含まれるclose_collegeを使用 data(&quot;NMES1988&quot;, package = &quot;AER&quot;) raw &lt;- NMES1988 3.1 Y=連続、Xカテゴリ 3.1.1 ヒストグラム: geom_histogram (tidyverse) 医療機関の利用回数 ggplot(raw, aes(x = visits) ) + geom_histogram() 保険の有無別 ggplot(raw, aes(x = visits, fill = insurance) ) + geom_histogram(position = &quot;identity&quot;, alpha = 0.5) 3.1.2 密度: geom_density (tidyverse) 保険の有無別分布 ggplot(raw, aes(x = visits, fill = insurance) ) + geom_density(position = &quot;identity&quot;, alpha = 0.5) 3.1.3 Boxplot: geom_boxplot (tidyverse) ggplot(raw, aes(y = visits, x = insurance) ) + geom_boxplot() 3.2 Y=連続、X=連続 3.2.1 散布図: geom_point (tidyverse) 散布図：連続変数間の関係性を可視化する図 ggplot(raw, aes(x = age, y = visits) ) + geom_point() サンプルサイズが大きくなると機能しない 3.2.2 ヒートマップ: geom_bin2d (tidyverse) 代替案はヒートマップ ggplot(raw, aes(x = age, y = visits) ) + geom_bin2d() "],["prediction.html", "Chapter 4 予測 4.1 問題設定 4.2 データの導入 4.3 データ分割 4.4 OLS 4.5 LASSO 4.6 Ridge 4.7 Bagging 4.8 Random Forest", " Chapter 4 予測 4.1 問題設定 データと同じ母集団から新しくランダムサンプリングされ、\\(X\\)のみが観察できるサンプルについて\\(Y\\)の値を予測することを目的とします。 具体的には、事前に定義する損失関数の期待値を最小化するような、予測関数\\(f(X)\\)の推定をめざします。 以下ではMean squared error(MSE)を損失関数として用います。 所与の\\(f(X)\\)、母分布に従う確率変数\\(Y,X\\)についてMSEは以下のように定義されます。 \\[MSE = E_{X,Y}[(Y_i-f(X_i))^2]\\] 一般にMSEは以下のように書き換えられます。 \\[MSE = \\underbrace{E_{X,Y}[(Y_i-\\bar{Y}(X_i))^2]}_{Irreducible\\ error}+\\underbrace{E_{X,Y}[(\\bar{Y}(X_i)-f(X_i))^2]}_{Reducible\\ error}\\] ただし\\(\\bar{Y}(X_i)=E[Y_i|X_i]\\)。 上記式から以下が確認できます。 最善の予測関数は条件付き母平均\\(\\bar{Y}(X_i)\\)(Reducible error = 0) 最善の予測関数のもとでも削減不可能なエラー(Irreducible error)が存在 予測関数の推定 \\(=\\) Reducible errorの削減 \\(=\\) 条件付き母平均との乖離(MSE)の削減 4.1.1 Bias-Variance tradeoff 実際の\\(f(X_i)\\)はランダムサンプリングされたデータから推定される必要があり、実際には確率分布を持ちます。 Reducible errorは一般に以下のように書き換えられます。 \\[E_{Y,X,f(X)}[(\\bar{Y}(X_i)-f(X_i))^2]\\] \\[=\\underbrace{(E_{Y,X,f(X)}[\\bar{Y}(X_i)-\\bar{f}(X_i)])^2}_{Bias}+\\underbrace{E_{Y,X,f(X)}[(\\bar{f}(X_i)-f(X_i))^2]}_{Variance}.\\] ただし\\(\\bar{f}(X_i)=f(X_i)\\)。 上記式は推定される予測関数が平均的にどの程度条件付き母平均を近似できているのか(Biasがどの程度小さいのか)だけでなく、予測関数の分布がどの程度散らばっているのか（VArianceがどの程度大木のか）、についても考慮する必要があることを示しています。 母平均\\(\\bar Y(X_i)\\)が単純な既知の関数形に従い、かつサンプルサイズが大きい場合、OLS推定された\\(f(X_i)\\)は\\(Bias=0\\)かつ小さいVarianceを達成します。 しかしながら社会科学における多くの応用においては、\\(\\bar Y(X_i)\\)は未知かつ複雑であることが予想され、その複雑さに対してサンプルサイズが小さいことを想定する必要があります。 このような状況では、OLSやサブサンプル平均により推定された予測モデルは、Bias-Variance tradeoffに直面します。 少ないパラメータ（短い回帰式、少ないサブサンプル分割）を推定する場合、大きなBiasを持つ 多くのパラメータ（長い回帰式、多いサブサンプル分割）を推定する場合、大きなVarianceを持つ。 Bias-variance tradeoffを分析者が解くこと（最善のモデル設定を行うこと）は困難です。Chapter 4 で紹介するLASSO/Ridge/Random Forestなどの手法は、bias-varianceのバランスをよりデータ主導型かつ現実的な計算時間で達成することを目指します。 4.2 データの導入 引き続きcausaldataに含まれるclose_collegeを使用 library(tidyverse) data(&quot;NMES1988&quot;, package = &quot;AER&quot;) raw &lt;- na.omit(NMES1988) set.seed(123) 4.3 データ分割 ここでは5個のデータに分割する。 group &lt;- sample(1:5, size = nrow(raw), replace = TRUE) 4.4 OLS 線形予測関数\\(f(X)=\\beta_0 + \\beta_1X_1+...+\\beta_LX_L\\)を仮定し、最小二乗法にて推定する。 fit &lt;- lm(visits ~ ., data = raw[group != 1,]) coef(fit) ## (Intercept) nvisits ovisits novisits emergency ## 3.531009562 0.255309552 0.071632543 0.115009115 0.354368910 ## hospital healthpoor healthexcellent chronic adllimited ## 1.424010008 1.600521748 -1.568712382 0.831439302 0.349098735 ## regionnortheast regionmidwest regionwest age afamyes ## 0.357607114 -0.357360750 0.355722082 -0.304177310 -0.364846004 ## gendermale marriedyes school income employedyes ## -0.387280327 -0.254584979 0.093203031 -0.005342627 0.541103638 ## insuranceyes medicaidyes ## 1.613683838 1.116443882 予測値の導出 Y.hat &lt;- predict(fit,raw) テストデータへの適合 mean((raw$visits - Y.hat)[group == 1]^2) ## [1] 38.92811 訓練データへの適合 mean((raw$visits - Y.hat)[group != 1]^2) ## [1] 37.57328 4.5 LASSO glmentパッケージ(Friedman et al. 2021)を利用 library(glmnet) Y &lt;- raw$visits X &lt;- model.matrix(visits ~ -1 + . + .^2 + I(age^2) + I(school^2) + I(income^2) + I(nvisits^2) + I(ovisits^2) + I(hospital^2), data = raw) cv &lt;- cv.glmnet(x = X[group != 1,], y = Y[group != 1], alpha = 1) fit &lt;- glmnet(x = X[group != 1,], y = Y[group != 1], alpha = 1, lambda = cv$lambda.min) 予測モデルの確認 coef(fit) ## 235 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s0 ## (Intercept) 4.189934686 ## nvisits . ## ovisits . ## novisits . ## emergency . ## hospital . ## healthpoor 0.388485676 ## healthaverage . ## healthexcellent . ## chronic 0.555773176 ## adllimited . ## regionnortheast . ## regionmidwest . ## regionwest . ## age . ## afamyes . ## gendermale . ## marriedyes . ## school . ## income . ## employedyes . ## insuranceyes . ## medicaidyes . ## I(age^2) . ## I(school^2) . ## I(income^2) . ## I(nvisits^2) . ## I(ovisits^2) . ## I(hospital^2) . ## nvisits:ovisits 0.030966031 ## nvisits:novisits . ## nvisits:emergency . ## nvisits:hospital 0.110839045 ## nvisits:healthpoor 0.023446950 ## nvisits:healthexcellent . ## nvisits:chronic . ## nvisits:adllimited 0.022998428 ## nvisits:regionnortheast 0.102031001 ## nvisits:regionmidwest . ## nvisits:regionwest . ## nvisits:age . ## nvisits:afamyes . ## nvisits:gendermale . ## nvisits:marriedyes . ## nvisits:school . ## nvisits:income . ## nvisits:employedyes . ## nvisits:insuranceyes 0.062931233 ## nvisits:medicaidyes . ## ovisits:novisits . ## ovisits:emergency . ## ovisits:hospital . ## ovisits:healthpoor . ## ovisits:healthexcellent . ## ovisits:chronic . ## ovisits:adllimited . ## ovisits:regionnortheast . ## ovisits:regionmidwest . ## ovisits:regionwest . ## ovisits:age . ## ovisits:afamyes . ## ovisits:gendermale . ## ovisits:marriedyes . ## ovisits:school . ## ovisits:income . ## ovisits:employedyes . ## ovisits:insuranceyes . ## ovisits:medicaidyes . ## novisits:emergency . ## novisits:hospital . ## novisits:healthpoor . ## novisits:healthexcellent . ## novisits:chronic . ## novisits:adllimited . ## novisits:regionnortheast . ## novisits:regionmidwest . ## novisits:regionwest . ## novisits:age . ## novisits:afamyes . ## novisits:gendermale . ## novisits:marriedyes . ## novisits:school 0.001667268 ## novisits:income . ## novisits:employedyes . ## novisits:insuranceyes . ## novisits:medicaidyes . ## emergency:hospital . ## emergency:healthpoor . ## emergency:healthexcellent . ## emergency:chronic . ## emergency:adllimited . ## emergency:regionnortheast . ## emergency:regionmidwest . ## emergency:regionwest . ## emergency:age . ## emergency:afamyes . ## emergency:gendermale . ## emergency:marriedyes . ## emergency:school . ## emergency:income . ## emergency:employedyes . ## emergency:insuranceyes . ## emergency:medicaidyes . ## hospital:healthpoor . ## hospital:healthexcellent . ## hospital:chronic . ## hospital:adllimited . ## hospital:regionnortheast . ## hospital:regionmidwest . ## hospital:regionwest . ## hospital:age . ## hospital:afamyes . ## hospital:gendermale . ## hospital:marriedyes . ## hospital:school 0.010204698 ## hospital:income . ## hospital:employedyes 0.548612203 ## hospital:insuranceyes 1.035816263 ## hospital:medicaidyes . ## healthpoor:chronic . ## healthexcellent:chronic . ## healthpoor:adllimited . ## healthexcellent:adllimited . ## healthpoor:regionnortheast . ## healthexcellent:regionnortheast . ## healthpoor:regionmidwest . ## healthexcellent:regionmidwest . ## healthpoor:regionwest . ## healthexcellent:regionwest . ## healthpoor:age . ## healthexcellent:age . ## healthpoor:afamyes . ## healthexcellent:afamyes . ## healthpoor:gendermale . ## healthexcellent:gendermale . ## healthpoor:marriedyes . ## healthexcellent:marriedyes . ## healthpoor:school . ## healthexcellent:school . ## healthpoor:income . ## healthexcellent:income . ## healthpoor:employedyes 1.254093720 ## healthexcellent:employedyes . ## healthpoor:insuranceyes . ## healthexcellent:insuranceyes . ## healthpoor:medicaidyes . ## healthexcellent:medicaidyes . ## chronic:adllimited . ## chronic:regionnortheast . ## chronic:regionmidwest . ## chronic:regionwest . ## chronic:age . ## chronic:afamyes . ## chronic:gendermale . ## chronic:marriedyes . ## chronic:school 0.011816478 ## chronic:income . ## chronic:employedyes . ## chronic:insuranceyes . ## chronic:medicaidyes . ## adllimited:regionnortheast . ## adllimited:regionmidwest . ## adllimited:regionwest . ## adllimited:age . ## adllimited:afamyes . ## adllimited:gendermale . ## adllimited:marriedyes . ## adllimited:school . ## adllimited:income . ## adllimited:employedyes . ## adllimited:insuranceyes . ## adllimited:medicaidyes . ## regionnortheast:age . ## regionmidwest:age . ## regionwest:age . ## regionnortheast:afamyes . ## regionmidwest:afamyes . ## regionwest:afamyes . ## regionnortheast:gendermale . ## regionmidwest:gendermale . ## regionwest:gendermale . ## regionnortheast:marriedyes . ## regionmidwest:marriedyes . ## regionwest:marriedyes . ## regionnortheast:school . ## regionmidwest:school . ## regionwest:school . ## regionnortheast:income . ## regionmidwest:income . ## regionwest:income . ## regionnortheast:employedyes . ## regionmidwest:employedyes . ## regionwest:employedyes . ## regionnortheast:insuranceyes . ## regionmidwest:insuranceyes . ## regionwest:insuranceyes . ## regionnortheast:medicaidyes . ## regionmidwest:medicaidyes . ## regionwest:medicaidyes . ## age:afamyes . ## age:gendermale . ## age:marriedyes . ## age:school . ## age:income . ## age:employedyes . ## age:insuranceyes . ## age:medicaidyes . ## afamyes:gendermale . ## afamyes:marriedyes . ## afamyes:school . ## afamyes:income . ## afamyes:employedyes . ## afamyes:insuranceyes . ## afamyes:medicaidyes . ## gendermale:marriedyes . ## gendermale:school . ## gendermale:income . ## gendermale:employedyes . ## gendermale:insuranceyes . ## gendermale:medicaidyes . ## marriedyes:school . ## marriedyes:income . ## marriedyes:employedyes . ## marriedyes:insuranceyes . ## marriedyes:medicaidyes . ## school:income . ## school:employedyes . ## school:insuranceyes . ## school:medicaidyes . ## income:employedyes . ## income:insuranceyes . ## income:medicaidyes . ## employedyes:insuranceyes . ## employedyes:medicaidyes . ## insuranceyes:medicaidyes . 予測値の導出 Y.hat &lt;- predict(fit,X) テストデータへの適合 mean((Y - Y.hat)[group == 1]^2) ## [1] 38.87397 訓練データへの適合 mean((Y - Y.hat)[group != 1]^2) ## [1] 37.32271 4.6 Ridge 引き続きglmentパッケージ(Friedman et al. 2021)を利用 cv &lt;- cv.glmnet(x = X[group != 1,], y = Y[group != 1], alpha = 0) fit &lt;- glmnet(x = X[group != 1,], y = Y[group != 1], alpha = 0, lambda = cv$lambda.min) 予測値の導出 Y.hat &lt;- predict(fit,X) テストデータへの適合 mean((Y - Y.hat)[group == 1]^2) ## [1] 39.6995 訓練データへの適合 mean((Y - Y.hat)[group != 1]^2) ## [1] 35.85782 4.6.1 No penalty library(glmnet) Y &lt;- raw$visits X &lt;- model.matrix(visits ~ -1 + . + .^2 + I(age^2) + I(school^2) + I(income^2), data = raw) fit &lt;- glmnet(x = X[group != 1,], y = Y[group != 1], alpha = 1, lambda = 0) 予測値の導出 Y.hat &lt;- predict(fit,X) テストデータへの適合 mean((Y - Y.hat)[group == 1]^2) ## [1] 132.806 訓練データへの適合 mean((Y - Y.hat)[group != 1]^2) ## [1] 30.72286 4.7 Bagging rangerパッケージ(Wright, Wager, and Probst 2020)を利用 library(ranger) X &lt;- model.matrix(visits ~ -1 + ., data = raw) fit &lt;- ranger(x = X[group != 1,], y = Y[group != 1], num.trees = 2000, mtry = ncol(X)) 予測値の計算 Y.hat &lt;- predict(fit,X)$predictions テストデータへの適合 mean((Y - Y.hat)[group == 1]^2) ## [1] 41.12654 訓練データへの適合 mean((Y - Y.hat)[group != 1]^2) ## [1] 8.307017 4.8 Random Forest 引き続きrangerパッケージ(Wright, Wager, and Probst 2020)を利用 fit &lt;- ranger(x = X[group != 1,], y = Y[group != 1], num.trees = 2000) 予測値の計算 Y.hat &lt;- predict(fit,X)$predictions テストデータへの適合 mean((Y - Y.hat)[group == 1]^2) ## [1] 37.99072 訓練データへの適合 mean((Y - Y.hat)[group != 1]^2) ## [1] 12.29817 "],["比較因果推論.html", "Chapter 5 比較・因果推論 5.1 比較 5.2 因果効果", " Chapter 5 比較・因果推論 5.1 比較 Chapter 6 の背後にある問題意識・方針を紹介します。 5.1.1 問題設定 変数\\(D\\)の値が異なる集団間において、結果変数\\(Y\\)の分布がどの程度異なっているのか、推定します。 その際直接的な関心ではない変数群\\(X\\)は一定であるとします。 以下の議論では\\(Y\\)の平均値に焦点を当て、\\(E[Y|D=d,X]-E[Y|D=d&#39;,X]\\)の推定を目指します。 またこの際に点推定量のみならず、信頼区間の推定も行います。 5.1.2 推定上の問題 重回帰やマッチング法などの古典的な推定手法は、依然として広く用いられています。 とくに条件づける必要がある\\(X\\)の数がサンプルサイズと比べて少数である場合、有効な手段となります。 多数の\\(X\\)で条件づける必要がある場合、重回帰やマッチング法などの手法の有効性が失われます。 これは予測で問題となった大きすぎるvarianceが生じてしまうためです。 なお\\(X\\)が少数であったとしても、定式化の自由度（高次項や交差項の導入）を持たせた場合、同様の問題が生じます。 この問題を回避するためにChapter 6 では、LASSOやRandom Forestなどの予測手法の応用を紹介します。 5.2 因果効果 引き続きChapter 6 の背後にある問題意識・方針を紹介します。 5.2.1 問題設定 ある集団の変数\\(D\\)を変化させた場合、結果変数\\(Y\\)の分布がどのように変化するのか、因果効果を推定します。 5.2.2 識別の問題 因果効果を推定する際には、識別条件をまず議論する必要があります。 識別条件：「仮にサンプルサイズが無限大である」場合、どのような仮定の下で因果効果を推定できるか？ 本ページでは以下の仮定に基づき議論していきます。 \\(0&lt;\\Pr[D_i=d|X_i]&lt;1\\): サブグループにおいても、原因変数の値にバリエーションが存在する。 ある個人の結果変数は、他者の原因変数の値に依存しない \\(X\\)が均一のグループ内では、\\(D\\)の値がランダムに決定されている） 以上の仮定のもとで\\(D\\)の因果効果は、\\(E[Y|D=d,X]-E[Y|D=d&#39;,X]\\)によって識別できます。 代替的な識別条件も複数存在 5.2.3 推定の問題 識別条件はしばしば多数の\\(X\\)について、条件づけた平均差の推定を要求されます このような状況では比較の問題と同様に、機械学習の応用が有益となります。 "],["unique.html", "Chapter 6 部分線形モデルの推定 6.1 データ 6.2 線形モデルの推定 6.3 マッチング法による修正 6.4 部分推計モデルの推定", " Chapter 6 部分線形モデルの推定 （条件付き）平均差の周辺化値の推定を目指します。 モデルに関心のあるパラメータを埋め込み、推定します。 \\[E[Y|D=d,X=x]=\\underbrace{\\tau}_{Interest\\ parameter}\\times d+\\underbrace{f(x)}_{Nuisance\\ function}\\] 点推定だけでなく、信頼区間も推定する。 6.1 データ library(tidyverse) data(&quot;NMES1988&quot;, package = &quot;AER&quot;) raw &lt;- na.omit(NMES1988) raw &lt;- mutate(raw, no_insurance = if_else(insurance == &quot;no&quot;,1, 0)) set.seed(123) 6.2 線形モデルの推定 \\(\\tau(x)=\\tau,f(x)=\\beta_0+\\beta_1x_1+...+\\beta_Lx_L\\)と特定化 サンプル内MSEを最大化するように推定 robust standard errorを計算するためにestimatrパッケージ(Blair et al. 2021)を利用 library(estimatr) lm_robust関数で推定 lm_robust(visits ~ no_insurance + region + age + afam + gender + school, data = raw) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 4.54907549 1.20748732 3.7673898 0.0001671226 2.18179218 ## no_insurance -0.89651959 0.24500870 -3.6591336 0.0002560368 -1.37686005 ## regionnortheast 0.35604317 0.30412286 1.1707215 0.2417741833 -0.24019081 ## regionmidwest -0.39742720 0.25426862 -1.5630210 0.1181196168 -0.89592176 ## regionwest 0.54872702 0.30377478 1.8063614 0.0709302595 -0.04682454 ## age 0.12381338 0.15107220 0.8195643 0.4125089371 -0.17236421 ## afamyes -0.34591740 0.34411264 -1.0052447 0.3148343575 -1.02055148 ## gendermale -0.63041288 0.20831504 -3.0262475 0.0024904316 -1.03881527 ## school 0.07205651 0.02986636 2.4126310 0.0158785157 0.01350340 ## CI Upper DF ## (Intercept) 6.9163588 4397 ## no_insurance -0.4161791 4397 ## regionnortheast 0.9522772 4397 ## regionmidwest 0.1010674 4397 ## regionwest 1.1442786 4397 ## age 0.4199910 4397 ## afamyes 0.3287167 4397 ## gendermale -0.2220105 4397 ## school 0.1306096 4397 発展:推計結果表 tidy関数により推定結果data.frameに変化することで、kable関数(knitrパッケージ)による推計結果表の整形、geom_pointrange関数による可視化が可能 点推定値(estimate)、標準誤差(std.error)のみを残した推計結果表 library(knitr) fit &lt;- lm_robust(visits ~ no_insurance + region + age + afam + gender + school, data = raw) fit &lt;- tidy(fit) fit &lt;- select(fit, term, estimate, std.error) kable(fit, digits = 2) term estimate std.error (Intercept) 4.55 1.21 no_insurance -0.90 0.25 regionnortheast 0.36 0.30 regionmidwest -0.40 0.25 regionwest 0.55 0.30 age 0.12 0.15 afamyes -0.35 0.34 gendermale -0.63 0.21 school 0.07 0.03 fit &lt;- filter(fit, term == &quot;no_insurance&quot;) kable(fit, digits = 2) term estimate std.error no_insurance -0.9 0.25 発展:Dot-and-Whisker plotによる可視化 Dot-and-Whisker図により点推定量と信頼区間を可視化 fit &lt;- lm_robust(visits ~ no_insurance + region + age + afam + gender + school, data = raw) fit &lt;- tidy(fit) fit &lt;- filter(fit, term != &quot;(Intercept)&quot;) ggplot(fit, aes(y = term, x = estimate, xmin = conf.low, xmax = conf.high)) + geom_pointrange() fit &lt;- filter(fit, term == &quot;no_insurance&quot;) ggplot(fit, aes(y = term, x = estimate, xmin = conf.low, xmax = conf.high)) + geom_pointrange() + geom_vline(xintercept = 0) 6.3 マッチング法による修正 library(MatchIt) 6.3.1 Nearest neighbor matching fit.m &lt;- matchit(no_insurance ~ region + age + afam + gender + school, data = raw, method = &quot;nearest&quot;) sum.m &lt;- summary(fit.m) plot(sum.m, xlim=c(0,2)) df &lt;- match.data(fit.m) lm_robust(visits ~ no_insurance + region + age + afam + gender + school, df, clusters = subclass, weights = weights) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 4.03758583 1.7329025 2.3299556 0.020224920 0.63251758 ## no_insurance -0.86928716 0.2984279 -2.9128888 0.003662714 -1.45492188 ## regionnortheast 0.66810128 0.4602372 1.4516455 0.147322247 -0.23646820 ## regionmidwest -1.00195066 0.3675805 -2.7257991 0.006712388 -1.72470450 ## regionwest 1.01297427 0.3883972 2.6080887 0.009408109 0.24967419 ## age 0.25926478 0.2107944 1.2299413 0.219334238 -0.15495116 ## afamyes -0.37043032 0.3439426 -1.0770121 0.281984225 -1.04614954 ## gendermale -0.90678819 0.3021627 -3.0009931 0.002772533 -1.49989137 ## school 0.01480405 0.0383591 0.3859332 0.699740085 -0.06059402 ## CI Upper DF ## (Intercept) 7.44265409 476.8893 ## no_insurance -0.28365244 975.1724 ## regionnortheast 1.57267076 434.2548 ## regionmidwest -0.27919682 378.8007 ## regionwest 1.77627435 449.4157 ## age 0.67348072 470.0911 ## afamyes 0.30528890 509.8327 ## gendermale -0.31368501 820.2442 ## school 0.09020212 423.2469 6.3.2 Coarsened exact matching fit.m &lt;- matchit(no_insurance ~ region + age + afam + gender + school, data = raw, method = &quot;cem&quot;, k2k = TRUE) sum.m &lt;- summary(fit.m) plot(sum.m, xlim=c(0,2)) df &lt;- match.data(fit.m) lm_robust(visits ~ no_insurance + region + age + afam + gender + school, df, clusters = subclass, weights = weights) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 3.561410841 2.47695497 1.43781816 0.1519930555 -1.32183233 ## no_insurance -0.547745400 0.34477470 -1.58870531 0.1126392066 -1.22481957 ## regionnortheast 0.175756782 0.57402808 0.30618151 0.7597632267 -0.95569711 ## regionmidwest -1.501779273 0.39984093 -3.75594183 0.0002175475 -2.28948860 ## regionwest 0.968830854 0.52763059 1.83619160 0.0678536818 -0.07177177 ## age 0.336254020 0.30422545 1.10527907 0.2703522931 -0.26360780 ## afamyes -0.717320069 0.52001127 -1.37943176 0.1700910410 -1.74594103 ## gendermale -1.262136493 0.35940647 -3.51172444 0.0004878990 -1.96836727 ## school 0.002509658 0.05155103 0.04868299 0.9612250738 -0.09920176 ## CI Upper DF ## (Intercept) 8.4446540 207.3593 ## no_insurance 0.1293288 616.9999 ## regionnortheast 1.3072107 214.6445 ## regionmidwest -0.7140699 236.2350 ## regionwest 2.0094335 194.7769 ## age 0.9361158 202.1698 ## afamyes 0.3113009 132.1769 ## gendermale -0.5559057 473.0157 ## school 0.1042211 182.8299 6.4 部分推計モデルの推定 部分線形モデルをロビンソン変換(Robinson 1988) \\[Y_i-\\underbrace{E[Y_i|X_i]}_{Nuisance\\ term}=\\tau\\times [D_i-\\underbrace{E[D_i|X_i]}_{Nuisance\\ term}]+u_i\\] \\(E[Y_i|X_i],E[D_i|X_i]\\)を予測関数として推定し、予測誤差間を単回帰すればよい 実際には\\(E[Y_i|X_i],E[D_i|X_i]\\)は未知の関数なので何らかの方法で推定する必要がある。関数の推定なので予測の手法が適用できる。 6.4.0.1 Double selection: rlassoEffect (hdm) 2重選択法(Belloni, Chernozhukov, and Hansen 2014)を紹介 LASSOにより\\(Y_i,D_i\\)の両方あるいはどちらか一方を予測する上でrelevantな\\(X^c\\)を特定しコントロールする \\(Y_i,D_i\\)どちらの予測にもrelevantではない変数は除外する hdmパッケージ(Spindler, Chernozhukov, and Hansen 2019)を利用 library(hdm) Y &lt;- raw$visits D &lt;- raw$no_insurance X &lt;- model.matrix(~ - 1+ region + age + afam + gender + school + I(age^2) + I(school^2) + region:age + region:afam + region:gender + region:school + age:afam + age:gender + age:school + afam:gender + afam:school + gender:school, raw) fit &lt;- rlassoEffect(x = X, y = Y, d = D, method = &quot;double selection&quot;) 推定結果 summary(fit) ## [1] &quot;Estimates and significance testing of the effect of target variables&quot; ## Estimate. Std. Error t value Pr(&gt;|t|) ## d1 -0.8642 0.2452 -3.524 0.000425 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 選択されたコントロール変数 fit$selection.index ## regionnortheast regionmidwest ## FALSE TRUE ## regionwest regionother ## FALSE FALSE ## age afamyes ## FALSE FALSE ## gendermale school ## FALSE TRUE ## I(age^2) I(school^2) ## FALSE FALSE ## regionnortheast:age regionmidwest:age ## FALSE FALSE ## regionwest:age regionnortheast:afamyes ## FALSE FALSE ## regionmidwest:afamyes regionwest:afamyes ## FALSE FALSE ## regionnortheast:gendermale regionmidwest:gendermale ## FALSE FALSE ## regionwest:gendermale regionnortheast:school ## FALSE FALSE ## regionmidwest:school regionwest:school ## FALSE FALSE ## age:afamyes age:gendermale ## TRUE FALSE ## age:school afamyes:gendermale ## TRUE FALSE ## afamyes:school gendermale:school ## FALSE FALSE 6.4.0.2 Double Machine Learning (DoubleML) Double Machine Learning法(Chernozhukov et al. 2018)を紹介 なんらかの方法（例、OLS、ランダムフォレスト、LASSO）で\\(E[Y|X],E[D|X]\\)の予測関数\\(f_Y(X),f_D(X)\\)を推定し、予測誤差を単回帰 DoubleMLパッケージ(Bach et al. 2021)を利用 library(DoubleML) library(mlr3) library(mlr3learners) library(data.table) X &lt;- model.matrix(~ - 1+ region + age + afam + gender + school, raw) learner &lt;- lrn(&quot;regr.ranger&quot;, num.trees = 100) # Require bigger num.trees in practice ml_g &lt;- learner$clone() ml_m &lt;- learner$clone() obj_dml_data &lt;- double_ml_data_from_matrix(X = X, y = as.numeric(Y), d = as.numeric(D)) dml_plr_obj &lt;- DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, dml_procedure=&quot;dml1&quot;, n_rep = 3) dml_plr_obj$fit() ## INFO [19:43:33.076] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 3/5) ## INFO [19:43:33.406] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 1/5) ## INFO [19:43:33.660] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 4/5) ## INFO [19:43:33.889] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 5/5) ## INFO [19:43:34.037] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 2/5) ## INFO [19:43:34.715] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 1/5) ## INFO [19:43:34.858] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 3/5) ## INFO [19:43:35.094] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 4/5) ## INFO [19:43:35.259] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 5/5) ## INFO [19:43:35.408] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 2/5) ## INFO [19:43:35.662] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 3/5) ## INFO [19:43:35.816] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 5/5) ## INFO [19:43:36.042] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 1/5) ## INFO [19:43:36.214] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 2/5) ## INFO [19:43:36.427] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 4/5) ## INFO [19:43:36.754] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 4/5) ## INFO [19:43:36.952] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 1/5) ## INFO [19:43:37.103] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 5/5) ## INFO [19:43:37.300] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 3/5) ## INFO [19:43:37.444] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 2/5) ## INFO [19:43:37.693] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 1/5) ## INFO [19:43:37.875] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 3/5) ## INFO [19:43:38.022] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 5/5) ## INFO [19:43:38.173] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 2/5) ## INFO [19:43:38.362] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 4/5) ## INFO [19:43:38.665] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 3/5) ## INFO [19:43:38.832] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 1/5) ## INFO [19:43:38.994] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 2/5) ## INFO [19:43:39.169] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 4/5) ## INFO [19:43:39.313] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 5/5) print(dml_plr_obj) ## ================= DoubleMLPLR Object ================== ## ## ## ------------------ Data summary ------------------ ## Outcome variable: y ## Treatment variable(s): d ## Covariates: X1, X2, X3, X4, X5, X6, X7, X8 ## Instrument(s): ## No. Observations: 4406 ## ## ------------------ Score &amp; algorithm ------------------ ## Score function: partialling out ## DML algorithm: dml1 ## ## ------------------ Machine learner ------------------ ## ml_g: regr.ranger ## ml_m: regr.ranger ## ## ------------------ Resampling ------------------ ## No. folds: 5 ## No. repeated sample splits: 3 ## Apply cross-fitting: TRUE ## ## ------------------ Fit summary ------------------ ## [1] &quot;Estimates and significance testing of the effect of target variables&quot; ## Estimate. Std. Error t value Pr(&gt;|t|) ## d -1.0325 0.2446 -4.222 2.43e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "],["条件付き平均効果関数の推定.html", "Chapter 7 条件付き平均効果関数の推定 7.1 Casual Forest 7.2 Distribution of predicted individual effects 7.3 Best linear predictors 7.4 Tree presentation", " Chapter 7 条件付き平均効果関数の推定 library(tidyverse) data(&quot;NMES1988&quot;, package = &quot;AER&quot;) raw &lt;- na.omit(NMES1988) raw &lt;- mutate(raw, no_insurance = if_else(insurance == &quot;no&quot;,1, 0)) Y &lt;- raw$visits D &lt;- raw$no_insurance X &lt;- model.matrix(~ - 1+ region + age + afam + gender + school, raw) set.seed(123) 7.1 Casual Forest library(grf) fit &lt;- regression_forest(X = X, Y = Y) Y.hat &lt;- predict(fit)$predictions fit &lt;- regression_forest(X = X, Y = D) D.hat &lt;- predict(fit)$predictions fit.CF &lt;- causal_forest(X = X, W = D, Y = Y, Y.hat = Y.hat, W.hat = D.hat) df &lt;- mutate(raw, tau.grf = predict(fit.CF)$predictions) 7.2 Distribution of predicted individual effects ggplot(df, aes(x = tau.grf) ) + geom_histogram() 7.3 Best linear predictors best_linear_projection(fit.CF,X) ## ## Best linear projection of the conditional average treatment effect. ## Confidence intervals are cluster- and heteroskedasticity-robust (HC3): ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.878656 3.080563 -0.2852 0.77548 ## regionnortheast -1.833887 0.771118 -2.3782 0.01744 * ## regionmidwest -1.143741 0.707519 -1.6166 0.10605 ## regionwest -0.058262 0.850668 -0.0685 0.94540 ## age 0.158464 0.378459 0.4187 0.67545 ## afamyes 0.330666 0.759248 0.4355 0.66321 ## gendermale -0.246440 0.554706 -0.4443 0.65687 ## school -0.083785 0.075749 -1.1061 0.26875 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 7.4 Tree presentation library(rpart) library(rpart.plot) fit &lt;- rpart(tau.grf ~ region + age + afam + gender + school + medicaid, df, control = rpart.control(cp = 0, maxdepth = 2) ) rpart.plot(fit) "],["references.html", "References", " References Bach, Philipp, Victor Chernozhukov, Malte S. Kurz, and Martin Spindler. 2021. DoubleML: Double Machine Learning in r. https://CRAN.R-project.org/package=DoubleML. Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014. “Inference on Treatment Effects After Selection Among High-Dimensional Controls.” The Review of Economic Studies 81 (2): 608–50. Blair, Graeme, Jasper Cooper, Alexander Coppock, Macartan Humphreys, and Luke Sonnet. 2021. Estimatr: Fast Estimators for Design-Based Inference. https://CRAN.R-project.org/package=estimatr. Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/Debiased Machine Learning for Treatment and Structural Parameters: Double/Debiased Machine Learning.” The Econometrics Journal 21 (1). Friedman, Jerome, Trevor Hastie, Rob Tibshirani, Balasubramanian Narasimhan, Kenneth Tay, and Noah Simon. 2021. Glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models. https://CRAN.R-project.org/package=glmnet. James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An Introduction to Statistical Learning. Vol. 112. Springer. Kleiber, Christian, and Achim Zeileis. 2008. Applied Econometrics with R. New York: Springer-Verlag. https://CRAN.R-project.org/package=AER. Robinson, Peter. 1988. “Root-n-Consistent Semiparametric Regression.” Econometrica 56 (4): 931–54. Sjoberg, Daniel D., Michael Curry, Margie Hannum, Joseph Larmarange, Karissa Whiting, and Emily C. Zabor. 2021. Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables. https://CRAN.R-project.org/package=gtsummary. Spindler, Martin, Victor Chernozhukov, and Christian Hansen. 2019. Hdm: High-Dimensional Metrics. https://CRAN.R-project.org/package=hdm. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain Francois, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2020. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2. Wickham, Hadley, Romain Francois, Lionel Henry, and Kirill Muller. 2021. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr. Wright, Marvin N., Stefan Wager, and Philipp Probst. 2020. Ranger: A Fast Implementation of Random Forests. https://github.com/imbs-hl/ranger. "]]
