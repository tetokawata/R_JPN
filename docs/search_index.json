[["index.html", "Rによる比較・予測・因果推論入門 ver0.2 はじめに", " Rによる比較・予測・因果推論入門 ver0.2 川田恵介 2022-02-23 はじめに 定量的な比較、（反実仮想）因果推定、予測分析をRによって行う方法を紹介 経済学におけるデータ分析の大部分は、複数の変数間での関係性の理解・利用を目的とする。 本ページでは、ある結果変数\\(Y\\)と独立変数（群）\\(X=X_1,...,X_L\\)の関係性に焦点を当てる。 また\\(Y\\)と\\(X\\)がともに観察でき、関心のある母集団からランダムサンプリングされたデータが入手出来ているとする。 各推定手法は、推定上の目標（識別結果）から導かれる推定すべき母集団の特徴に応じて、整理される。ここで論じる推定上の目標は以下の３つである。 （予測）\\(Y\\)の予測関数の推定 （比較）異なる\\(X\\)間での\\(Y\\)の比較 （因果効果）\\(X\\)の変化が\\(Y\\)に与える因果効果の推定 分析環境の主な特徴は、以下のパッケージ群の利用にある データインポート、整理、可視化を行う関数群を統合的に提供する[tidyverseパッケージ] (Wickham et al. 2019)の利用 Robust standard errorを簡潔に計算するestimatrパッケージ (Blair et al. 2022a)の利用 Stacking法を簡潔に実装するSuperLearnerパッケージ (Van der Laan, Polley, and Hubbard 2007)の利用 R nativeなパイプ演算子 “|&gt;” の利用 Example dataとしては、AERパッケージ (Kleiber and Zeileis 2008)に含まれるPSID1982 (Panel Study on Income Dynamics)を利用 References "],["intro.html", "Chapter 1 概念整理 1.1 推定のゴール 1.2 応用方法", " Chapter 1 概念整理 本稿では条件付き母平均関数の推定とその応用に焦点を絞る 条件付き母平均関数は以下で定義される \\[\\mu(w)=E[Y_i|W_i=w]\\] 一般にデータから、条件付き母平均関数を”完璧”に推定することは不可能である。このため”妥協を伴う”ゴールを適切に設定する必要がある 1.1 推定のゴール 大きく二つのゴールがある 条件付き母平均関数 \\(\\mu(w)\\) の近似： 平均二乗誤差 \\(E[(\\mu(w) - f(w))^2]\\) を可能な限り削減する様に \\(f(w)\\) を推定 関心のある変数 \\(d\\) について、記述モデルを推定: \\(\\tau(d,d&#39;,x)=\\mu(d,x)-\\mu(d&#39;,x)\\) の重要な”特徴”を捉える単純化されたモデルを推定する 1.2 応用方法 推定結果は以下のように応用できる \\(f(w)\\) の応用: \\(Y\\) の予測：データと同じ母集団から抽出された新たにサンプリ \\(i\\) について、 \\(W_i\\) から \\(Y_i\\) を予測するる。予測精度を平均二乗誤差で測定するのであれば母平均関数 \\(\\mu(w)\\) が最善の予測関数となり、その近似関数 \\(f(w)\\) が現実的な予測値となる \\(\\tau(x)\\) の応用: \\(D\\) が異なるグループ間での \\(Y\\) についての”格差”：変数\\(D_i\\)の値が異なる集団間において、結果変数\\(Y_i\\)の分布がどの程度異なっているのか、推定する。またこの際に、直接的な関心ではない変数群\\(X_i\\)を”一定”としたもとで、比較したいとする。全ての変数 \\(W\\) を考慮する訳ではないので、 \\(\\tau(d,d&#39;,x)\\) を適切に推定する必要がある \\(D\\) が \\(Y\\) に与える因果効果：ある集団の変数\\(D\\)を変化させた場合、結果変数\\(Y\\)の分布がどのように変化するのか、因果効果を推定する。 注意:因果効果を推定する際には、識別を議論する必要がある。 \\(\\tau(d,d&#39;,x)\\) は以下の識別の仮定の下で、\\(X_i=x\\) を満たす集団内での平均因果効果と一致する \\(0&lt;\\Pr[D_i=d|X_i]&lt;1\\): サブグループにおいても、原因変数の値にバリエーションが存在する。 \\(X\\)で条件づけた場合、潜在結果関数と原因変数の実現値が独立している\\(Y_i(d)\\perp D_i|X_i=x\\) 十分条件：同じ\\(X\\)グループ内では、\\(D\\)の値がランダムに決定されている 上記の仮定は、“selection-on-observable” と呼ばれ、多くの実践で用いられている。 この仮定の下では、\\(\\tau(d,d&#39;,x)\\) を適切に推定する必要がある。 E[Y_i|X_i=x]-_{xc}E[Y_i|X_i=x]$$ "],["prediction.html", "Chapter 2 予測 2.1 問題設定 2.2 パッケージ &amp; データ 2.3 事前準備 2.4 線形予測モデル 2.5 予測木モデル 2.6 Stacking", " Chapter 2 予測 条件つき母平均 \\(E[Y|X]\\) の近似関数 \\(f(X)\\) を推定する \\(E[(E[Y|X]-f(X))^2]\\) を削減 データと同じ母集団から新しくランダムサンプリングされた \\(Y\\) についての優れた予測関数 データ分割を用いたモデル評価も紹介する Chapter 2.1 : 予測問題の論点を紹介 Chapter 2.3 : データ分割 Chapter 2.4 : 線形モデルをOLS及び罰則付き回帰(LASSO, Ridge)で推定する手法を紹介 Chapter 2.5 : 予測木モデル、及びモデル平均加法(Bagging, Random Forest)を紹介 2.1 問題設定 事前に定義する損失関数の期待値を最小化するような、予測関数\\(f(X)\\)の推定を目指す。 本ページではMean squared error(MSE)を損失関数として用いるケースを紹介する。所与の\\(f(X)\\)、母分布に従う確率変数\\(Y,X\\)についてMSEは以下のように定義される。 \\[MSE = E_{X,Y}[(Y_i-f(X_i))^2]\\] 一般にMSEは以下のように書き換えられる。 \\[MSE = \\underbrace{E_{X,Y}[(Y_i-\\bar{Y}(X_i))^2]}_{Irreducible\\ error}+\\underbrace{E_{X,Y}[(\\bar{Y}(X_i)-f(X_i))^2]}_{Reducible\\ error}\\] ただし\\(\\bar{Y}(X_i)=E[Y_i|X_i]\\)。 上記式から以下が確認できる。 最善の予測関数 \\(\\iff\\) Reducible error \\(=0\\) \\(\\iff\\) 条件付き母平均\\(\\bar{Y}(X_i)\\) 最善の予測関数のもとでも削減不可能なエラー(Irreducible error)が存在 予測関数の推定 \\(=\\) Reducible errorの削減を要求 \\(=\\) 条件付き母平均との乖離(MSE)の削減を要求 2.1.1 Bias-Variance tradeoff 実際の\\(f(X_i)\\)はランダムサンプリングされたデータから推定される。このためデータの入手前の段階では、確率分布を持つ。 Reducible errorは一般に以下のように書き換えられます。 \\[E_{Y,X,f(X)}[(\\bar{Y}(X_i)-f(X_i))^2]\\] \\[=\\underbrace{(E_{Y,X,f(X)}[\\bar{Y}(X_i)-\\bar{f}(X_i)])^2}_{Bias}+\\underbrace{E_{Y,X,f(X)}[(\\bar{f}(X_i)-f(X_i))^2]}_{Variance}.\\] ただし\\(\\bar{f}(X_i)=f(X_i)\\)。 上記式は推定される予測関数が平均的にどの程度条件付き母平均を近似できているのか(Biasがどの程度小さいのか)だけでなく、予測関数の分布がどの程度散らばっているのか、についても考慮する必要性を示す。 母平均\\(\\bar Y(X_i)\\)が単純な既知の関数形に従い、かつサンプルサイズが大きい場合、OLS推定された\\(f(X_i)\\)は\\(Bias=0\\)かつ小さなVarianceを達成する。 社会科学における多くの応用においては、\\(\\bar Y(X_i)\\)は未知かつ複雑であることが予想され、その複雑さに対してサンプルサイズが小さいことが想定される。 このような状況では、深刻なBias-Variance tradeoffに直面する。 少ないパラメータ（短い回帰式、少ないサブサンプル分割）を推定する場合、大きなBiasを持つ 多くのパラメータ（長い回帰式、多いサブサンプル分割）を推定する場合、大きなVarianceを持つ。 Bias-variance tradeoffを分析者が先見的に解決することは一般に困難 @ref{LASSO} - ?? で紹介するLASSO/Ridge/Random Forestなどの手法は、bias-variance問題をよりデータ主導型かつ現実的な計算時間の手法で解決することを目指す。 2.2 パッケージ &amp; データ Rによる教師付き学習実装法には、大きく二つの有力な選択肢が存在する 個別の推定法を実装するパッケージ (例：LASSO &amp; Ridge \\(=\\) glmnet, Random Forest \\(=\\) ranger) を使用 dependencyを減らすことができ、パッケージの更新にも迅速に対応できる 個別パッケージで実装される手法を”共通”の文法で使用するメタパッケージ(例： caret, mlr3, tidymodels, SuerLeaner)を使用 初学者が色々な手法を試すことが容易 本ページでは、SuperLearnerの利用を前提にしている 他のメタパッケージに比べて”自由度”が低いが、コーディングに慣れていない読者にとっても比較的用意に使える（かも。。。） 後述するStacking法の実装を主目的としており、母集団への先見的知見が少ない社会科学において実用的 利用するパッケージ library(tidyverse) library(AER) library(SuperLearner) # 機械学習を実装するメタパッケージ library(rpart.plot) # 予測木の可視化 library(recipes) データ 元データを結果変数、予測変数データに分割する必要がある data(&quot;PSID1982&quot;) Y &lt;- PSID1982$wage |&gt; log() # 結果変数 X &lt;- recipe(~ experience + education + industry + south + smsa + married + union + ethnicity + gender, PSID1982) |&gt; step_other(all_nominal_predictors(), other = &quot;others&quot;) |&gt; step_unknown(all_nominal_predictors()) |&gt; step_indicate_na(all_numeric_predictors()) |&gt; step_impute_median(all_numeric_predictors()) |&gt; step_dummy(all_nominal_predictors()) |&gt; step_zv(all_numeric_predictors()) |&gt; prep() |&gt; bake(PSID1982) set.seed(123) 2.3 事前準備 ここでは5個のデータに分割する。 group &lt;- sample(1:5, # 1から5までの数字を発生される size = length(Y), # サンプルサイズと同数発生される replace = TRUE) # 同じ数字が発生することを許容する 第1データをテストデータ、2－5データを訓練データとして使用する 2.4 線形予測モデル 線形予測関数\\(f(X)=\\beta_0 + \\beta_1X_1+...+\\beta_LX_L\\)を想定 OLS: \\(\\beta_0,...,\\beta_L\\)を最小二乗法にて推定 \\[\\min\\sum_i (Y_i-f(X))^2\\] LASSO推定：線形モデルを以下の最適化問題の解として推定 \\[\\min\\sum_i (Y_i-f(X_i))^2+\\underbrace{\\lambda\\sum_l|\\beta_l|}_{Penalty\\ term}\\] \\(\\lambda\\) : チューニングパラメタ、Cross-validationを用いて設定可能 Ridge推定：線形モデルを以下の最適化問題の解として推定 \\[\\min\\sum_i (Y_i-f(X_i))^2+\\underbrace{\\lambda\\sum_l(\\beta_l)^2}_{Penalty\\ term}\\] \\(\\lambda\\) : チューニングパラメタ、Cross-validationを用いて設定可能 2.4.1 OLS fit &lt;- SuperLearner(Y = Y[group != 1], X = X[group != 1,], newX = X, SL.library = c(&quot;SL.lm&quot;), cvControl = list(V = 20L) ) # 推定 coef(fit$fitLibrary$SL.lm_All$object) # 係数値の表示 ## (Intercept) experience education industry_yes south_yes ## 5.755132262 0.003562848 0.069988183 0.076419213 -0.056988431 ## smsa_yes married_yes union_yes ethnicity_afam gender_female ## 0.196762284 0.115028991 0.087181055 -0.201797880 -0.343736336 元データ全体への予測値の計算 Y.pred &lt;- fit$SL.predict[,1] テストデータへの適合 mean((Y - Y.pred)[group == 1]^2) ## [1] 0.09619175 デフォルトの設定では、訓練データのみを用いた交差検証（10分割）の結果も自動的に計算されている fit ## ## Call: ## SuperLearner(Y = Y[group != 1], X = X[group != 1, ], newX = X, SL.library = c(&quot;SL.lm&quot;), ## cvControl = list(V = 20L)) ## ## ## Risk Coef ## SL.lm_All 0.1192825 1 Risk \\(=\\) 交差検証法で推定されたMSE Coef \\(=\\) 後述するStackingモデルにおけるOLSによる予測値へのweight 2.4.2 LASSO glmentパッケージ(Friedman et al. 2021)を利用 glmnetはdata.frameを直接の入力できず、matrix(vector)に変換する必要がある fit &lt;- SuperLearner(Y = Y[group != 1], X = X[group != 1,], newX = X, SL.library = c(&quot;SL.glmnet&quot;) ) coef(fit$fitLibrary$SL.glmnet_All$object) ## 10 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 6.1021592922 ## experience 0.0007651499 ## education 0.0537787290 ## industry_yes 0.0170376309 ## south_yes -0.0381726729 ## smsa_yes 0.1488379523 ## married_yes 0.1026549245 ## union_yes 0.0201281810 ## ethnicity_afam -0.1145501021 ## gender_female -0.3048826476 元データ全体への予測値の計算 Y.pred &lt;- fit$SL.predict[,1] テストデータへの適合 mean((Y - Y.pred)[group == 1]^2) ## [1] 0.09617926 交差検証 fit ## ## Call: ## SuperLearner(Y = Y[group != 1], X = X[group != 1, ], newX = X, SL.library = c(&quot;SL.glmnet&quot;)) ## ## ## ## Risk Coef ## SL.glmnet_All 0.1198278 1 2.4.3 Ridge learners = create.Learner(&quot;SL.glmnet&quot;, params = list(alpha = 0)) # glmnetのalphaを0（Ridge推定）に設定 fit &lt;- SuperLearner(Y = Y[group != 1], X = X[group != 1,], newX = X, SL.library = c(learners$names) ) coef(fit$fitLibrary$SL.glmnet_1_All$object) ## 10 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 6.23601716 ## experience 0.00163009 ## education 0.04008814 ## industry_yes 0.03479081 ## south_yes -0.06350106 ## smsa_yes 0.13136009 ## married_yes 0.12712923 ## union_yes 0.03456877 ## ethnicity_afam -0.16078323 ## gender_female -0.21611678 元データ全体への予測値の計算 Y.pred &lt;-fit$SL.predict[,1] テストデータへの適合 mean((Y - Y.pred)[group == 1]^2) ## [1] 0.09640949 交差検証 fit ## ## Call: ## SuperLearner(Y = Y[group != 1], X = X[group != 1, ], newX = X, SL.library = c(learners$names)) ## ## ## ## Risk Coef ## SL.glmnet_1_All 0.119792 1 2.5 予測木モデル 2.5.1 Tree 予測木を推定する 推定法は以下の通り ある変数\\(X\\)のある閾値\\(\\bar X\\)において、サンプルを分割する 分割後のサブサンプル平均を暫定的予測値とする 予測値と訓練データにおける結果変数の値の乖離(MSE)を最小にするように、分割に用いる変数と閾値を決定 １回目の分割結果を所与として、２回目の分割を決定。変数と閾値は１回目と同様の基準で決定。 以上を繰り返す 推定された予測木について、pruningを実行 fit &lt;- SuperLearner(Y = Y[group != 1], X = X[group != 1,], newX = X, SL.library = c(&quot;SL.rpartPrune&quot;) ) rpart.plot(fit$fitLibrary$SL.rpartPrune_All$object) # 予測木の可視化 元データ全体への予測値の計算 Y.pred &lt;- fit$SL.predict[,1] テストデータへの適合 mean((Y - Y.pred)[group == 1]^2) ## [1] 0.1084955 交差検証 fit ## ## Call: ## SuperLearner(Y = Y[group != 1], X = X[group != 1, ], newX = X, SL.library = c(&quot;SL.rpartPrune&quot;)) ## ## ## ## Risk Coef ## SL.rpartPrune_All 0.1382216 1 2.5.2 Random Forest Random Forestを推定する 多数の予測木を推定し、各予測値の平均値を最終予測値とする 平均を取ることで、予測値の分散削減が期待できる 予測木におけるサンプル分割において、ランダムに予測変数の部分集合を選ぶ 部分集合の中から、訓練データへの適合度が最大になるように分割を行う 各予測木の予測値の相関を減らし、平均化による分散削減を促進する fit &lt;- SuperLearner(Y = Y[group != 1], X = X[group != 1,], newX = X, SL.library = c(&quot;SL.ranger&quot;) ) 元データ全体への予測値の計算 Y.pred &lt;- fit$SL.predict[,1] テストデータへの適合 mean((Y - Y.pred)[group == 1]^2) ## [1] 0.08485928 交差検証 fit ## ## Call: ## SuperLearner(Y = Y[group != 1], X = X[group != 1, ], newX = X, SL.library = c(&quot;SL.ranger&quot;)) ## ## ## ## Risk Coef ## SL.ranger_All 0.1168173 1 2.6 Stacking SuperLearner関数の主目的は、複数の予測モデルを線型結合した予測モデル（Super learner: Van der Laan, Polley, and Hubbard (2007)）の推定 \\(f_k(x)\\)をアルゴリズム\\(k\\) (例：LASSO, Ridge, Random Forest)により推定された予測値とすると、SuperLearnerは以下のように定義される \\[f_{SL}(x)=\\beta_1 f_1(x)+...+\\beta_K f_{K}(x)\\] ただし, \\(\\beta_k \\in [0,1]\\)かつ\\(\\beta_1+...+\\beta_K=1\\) learners = create.Learner(&quot;SL.glmnet&quot;, params = list(alpha = 0)) # Ridge推定の定義 fit &lt;- SuperLearner(X = X[group != 1,], Y = Y[group != 1], newX = X, SL.library = c(&quot;SL.mean&quot;, &quot;SL.lm&quot;, &quot;SL.glmnet&quot;, &quot;SL.rpartPrune&quot;, &quot;SL.ranger&quot;, learners$names ) ) # モデル推定 &amp; 交差検証 fit ## ## Call: ## SuperLearner(Y = Y[group != 1], X = X[group != 1, ], newX = X, SL.library = c(&quot;SL.mean&quot;, ## &quot;SL.lm&quot;, &quot;SL.glmnet&quot;, &quot;SL.rpartPrune&quot;, &quot;SL.ranger&quot;, learners$names)) ## ## ## Risk Coef ## SL.mean_All 0.1983490 0.0000000 ## SL.lm_All 0.1197758 0.3796438 ## SL.glmnet_All 0.1197891 0.0000000 ## SL.rpartPrune_All 0.1466757 0.0000000 ## SL.ranger_All 0.1164411 0.6203562 ## SL.glmnet_1_All 0.1196649 0.0000000 Coef \\(= \\beta_k\\) 訓練データ内の交差検証では、glmnetにより実装されたLASSOによる予測値の性能が最もいいことが確認できる Stackingモデルにおいて、最もweightが大きいのはLASSO、続いてrangerであることが確認できる Stackingモデルの予測値 Y.pred &lt;- fit$SL.predict[,1] テストデータへの適合 mean((Y - Y.pred)[group == 1]^2) ## [1] 0.0855917 References "],["unique.html", "Chapter 3 線形モデルの推定 3.1 パッケージ &amp; データ 3.2 線形モデルの推定 3.3 マッチング法による修正", " Chapter 3 線形モデルの推定 関心のあるパラメータ\\(\\tau(X)=E[Y|d,X]-E[Y|d&#39;,X]\\)を埋め込んだ線形モデルを推定する。 典型的には、\\(E[Y|D,X]\\)を線形近似し、推定する。 \\[E[Y|D=d,X=x]=\\underbrace{\\tau}_{Interest\\ parameter}\\times d+\\underbrace{f(x)}_{Nuisance\\ function}\\] - \\(f(X)=\\beta_0 + \\beta_1 X_1 + ...+\\beta_LX_L\\) \\(\\tau\\)について点推定だけでなく、信頼区間も推定する。 Chapter 3.2 : 前処理なしに線形モデルを推定し、信頼区間を計算する方法を紹介 Chapter 3.3 : 近似モデルの定式化への依存度を下げるために、マッチング法を用いた前処理を導入 Chapter ?? : 推定結果の表によるまとめ、可視化、および複数の推定結果を効率的に保存する方法を紹介 3.1 パッケージ &amp; データ library(tidyverse) library(AER) library(estimatr) library(MatchIt) data(&quot;PSID1982&quot;) 3.2 線形モデルの推定 \\(\\tau(x)=\\tau,f(x)=\\beta_0+\\beta_1x_1+...+\\beta_Lx_L\\)と特定化 サンプル内MSEを最大化するように推定 robust standard errorを計算するためにestimatrパッケージ(Blair et al. 2022b)を利用 lm_robust関数で推定 lm_robust(log(wage) ~ occupation + education + south + smsa + gender + ethnicity + industry + weeks, data = PSID1982) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.3023136910 0.175077599 35.99725906 1.387672e-150 ## occupationblue -0.1395675030 0.037132508 -3.75863385 1.879532e-04 ## education 0.0510611291 0.007213451 7.07859910 4.179497e-12 ## southyes -0.0849846890 0.034214451 -2.48388287 1.327422e-02 ## smsayes 0.1793275171 0.030659738 5.84895787 8.226856e-09 ## genderfemale -0.4463245183 0.038664691 -11.54346517 6.436339e-28 ## ethnicityafam -0.1921038599 0.058100604 -3.30640037 1.002829e-03 ## industryyes 0.1073240453 0.030046094 3.57197991 3.834060e-04 ## weeks -0.0001191249 0.002944063 -0.04046274 9.677380e-01 ## CI Lower CI Upper DF ## (Intercept) 5.958457704 6.646169678 586 ## occupationblue -0.212496509 -0.066638497 586 ## education 0.036893763 0.065228495 586 ## southyes -0.152182571 -0.017786807 586 ## smsayes 0.119111164 0.239543870 586 ## genderfemale -0.522262763 -0.370386273 586 ## ethnicityafam -0.306214636 -0.077993084 586 ## industryyes 0.048312901 0.166335189 586 ## weeks -0.005901325 0.005663075 586 線形モデルによる推定は、いくつかの問題がある 異なるグループ間で、\\(X\\)の分布が異なる場合、回帰式の定式化に強く依存する 一般に平均効果ではなく、加重平均が推計される サンプルサイズに比べて、少数のコントロール変数を導入できない 以下ではマッチング法、機械学手法を用いた頑強な推定を目指す 3.2.1 RCTデータへの応用 原因変数が完全にランダム化されている場合、因果効果の識別を目的に回帰分析を応用する必要はない 因果効果の推定の改善、効率性向上、を目的として線形モデルの利用は議論されてきた。(Freedman et al. 2008; Freedman 2008) (Lin et al. 2013)は、以下のような交差項を導入したモデルを用いることで、平均の差の推定に比べて、漸近的効率性が悪化することはない（同等か改善する）ことを示した \\[E[Y|D,X]=\\beta_{D}\\times D+\\beta_1\\times X_1+...+\\beta_L\\times X_L\\] \\[+\\underbrace{\\beta_{1D}\\times D\\times X_1+...+\\beta_{LD}\\times D\\times X_L}_{交差項}\\] 3.3 マッチング法による修正 回帰を行う事前準備としてマッチング法を利用する 重回帰が持つ関数形への依存度を減らせる (Daniel E. Ho et al. 2007) MathItパッケージ (Daniel E. Ho et al. 2011)を利用 多数のマッチング法が実装されている 3.3.1 Exact matching \\(X\\)が完全に同じサンプル同士をマッチングする 原因変数の分布に偏りがある場合（本例ではコントロールグループが少ない）、少ないグループ内での平均効果(Average treatment effect for treat または control)の推定を目指すことでマッチできないサンプルを減らすことが期待できる。 fit.m &lt;- matchit(occupation ~ education + south + smsa + gender + ethnicity + industry + weeks, data = PSID1982, method = &quot;exact&quot;, estimand = &quot;ATC&quot; ) この例では、incomeもコントロール変数に加えた場合、Exact matching不可能（一つもマッチングできない） マッチング結果の表示 fit.m ## A matchit object ## - method: Exact matching ## - number of obs.: 595 (original), 164 (matched) ## - target estimand: ATC ## - covariates: education, south, smsa, gender, ethnicity, industry, weeks Sample sizesにて、マッチングできなかったサンプル数（985のコントロールグループ中、667サンプルがマッチングできなかった）が確認できる マッチング結果の図示 fit.m |&gt; summary() |&gt; plot(xlim = c(0,2)) マッチング結果を変数として含んだデータを作成 df &lt;- match.data(fit.m) “subclass”: マッチングしたグループ “weights”：マッチング後の推計に用いるウェイト マッチングしたデータを用いた推定 新たに作成されるweight (defaltではweights)を用いた、加重推定で実装 lm_robust(log(wage) ~ occupation, df, weights = weights) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 7.0420847 0.04994819 140.98778 2.070307e-171 6.9434512 ## occupationblue -0.1132829 0.06751827 -1.67781 9.531235e-02 -0.2466123 ## CI Upper DF ## (Intercept) 7.14071815 162 ## occupationblue 0.02004655 162 3.3.2 Coarsened exact matching Coarsened exact matching(Iacus, King, and Porro 2012)の実装 連続変数をカテゴリー変数化することで、マッチングできるサンプルサイズを増やすことが期待できる fit.m &lt;- matchit(occupation ~ education + south + smsa + gender + ethnicity + industry + weeks, data = PSID1982, method = &quot;cem&quot;, estimand = &quot;ATC&quot;) マッチング結果 fit.m ## A matchit object ## - method: Coarsened exact matching ## - number of obs.: 595 (original), 279 (matched) ## - target estimand: ATC ## - covariates: education, south, smsa, gender, ethnicity, industry, weeks 可視化 fit.m |&gt; summary() |&gt; plot(xlim = c(0,2)) Exact matching以外のマッチング法では、マッチングされたサンプル内でも\\(X\\)の違いが残る マッチングされたサンプル内で回帰分析を行うことで、再調整する df &lt;- match.data(fit.m) lm_robust(log(wage) ~ occupation + education + south + smsa + gender + ethnicity + industry + weeks, df, weights = weights) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 7.305267831 0.470201151 15.5364737 2.515246e-39 6.379540966 ## occupationblue -0.190660781 0.070749688 -2.6948639 7.483408e-03 -0.329951989 ## education 0.041323645 0.017944795 2.3028206 2.204947e-02 0.005994129 ## southyes 0.006005311 0.076041911 0.0789737 9.371120e-01 -0.143705170 ## smsayes 0.296308810 0.103188389 2.8715325 4.408722e-03 0.093152643 ## genderfemale -0.534957602 0.102689392 -5.2094729 3.762899e-07 -0.737131350 ## ethnicityafam -0.324068758 0.137890701 -2.3501857 1.948409e-02 -0.595546456 ## industryyes -0.012240212 0.050900941 -0.2404712 8.101474e-01 -0.112453426 ## weeks -0.019122771 0.009897325 -1.9321150 5.439142e-02 -0.038608517 ## CI Upper DF ## (Intercept) 8.2309946951 270 ## occupationblue -0.0513695723 270 ## education 0.0766531614 270 ## southyes 0.1557157913 270 ## smsayes 0.4994649767 270 ## genderfemale -0.3327838534 270 ## ethnicityafam -0.0525910603 270 ## industryyes 0.0879730014 270 ## weeks 0.0003629743 270 3.3.3 Propensity score with subclassification Coarsened exact matchingでもマッチングできないサンプルが多数出てくる可能性 とくに\\(X\\)が大量にある場合 1次元の距離指標を用いて、マッチングを行う 距離指標としては、Mahalanobis’ Distance、Propensity scoreなど ここではPropensity score \\(p_d(X)\\)を用いる \\[p_d(X)\\equiv \\Pr[D=d|X]\\] 属性\\(X\\)のユニットの中で、原因変数の値が\\(d\\)である人の割合 未知の場合、データから推定する必要がある 推定された傾向スコアを用いたStratification マッチング - ロジットにて傾向スコアを推定 fit.m &lt;- matchit(occupation ~ education + south + smsa + gender + ethnicity + industry + weeks, data = PSID1982, method = &quot;subclass&quot;, estimand = &quot;ATC&quot; ) マッチング結果 fit.m ## A matchit object ## - method: Subclassification (6 subclasses) ## - distance: Propensity score ## - estimated with logistic regression ## - number of obs.: 595 (original), 595 (matched) ## - target estimand: ATC ## - covariates: education, south, smsa, gender, ethnicity, industry, weeks マッチング結果の図示 fit.m |&gt; summary() |&gt; plot(xlim = c(0,2)) マッチングしたデータを用いた推定 df &lt;- match.data(fit.m) # マッチング結果を含んだ lm_robust(log(wage) ~ occupation + education + south + smsa + gender + ethnicity + industry + weeks, df, weights = weights) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 6.445657234 0.228167973 28.2496143 1.880233e-111 5.997530666 ## occupationblue -0.186704124 0.058965993 -3.1663017 1.624117e-03 -0.302514541 ## education 0.041386176 0.010950515 3.7793816 1.733061e-04 0.019879140 ## southyes -0.051691098 0.061819039 -0.8361679 4.034013e-01 -0.173104955 ## smsayes 0.279464109 0.087934075 3.1781094 1.560487e-03 0.106759786 ## genderfemale -0.440702842 0.040582880 -10.8593289 3.723360e-25 -0.520408448 ## ethnicityafam -0.297247615 0.074173427 -4.0074677 6.928814e-05 -0.442925744 ## industryyes 0.120204825 0.040286300 2.9837643 2.965829e-03 0.041081708 ## weeks -0.001910554 0.004069346 -0.4694990 6.388877e-01 -0.009902832 ## CI Upper DF ## (Intercept) 6.893783801 586 ## occupationblue -0.070893706 586 ## education 0.062893212 586 ## southyes 0.069722759 586 ## smsayes 0.452168431 586 ## genderfemale -0.360997235 586 ## ethnicityafam -0.151569487 586 ## industryyes 0.199327942 586 ## weeks 0.006081725 586 3.3.4 Nearest neighbor matching 傾向スコアを用いた最近旁マッチング 傾向スコアがもっとも似ているサンプルとマッチングする デフォルトでは、Replacement無しのマッチングを行う fit.m &lt;- matchit(occupation ~ education + south + smsa + gender + ethnicity + industry + weeks, data = PSID1982, method = &quot;nearest&quot;, estimand = &quot;ATC&quot; ) マッチング結果 fit.m ## A matchit object ## - method: 1:1 nearest neighbor matching without replacement ## - distance: Propensity score ## - estimated with logistic regression ## - number of obs.: 595 (original), 580 (matched) ## - target estimand: ATC ## - covariates: education, south, smsa, gender, ethnicity, industry, weeks マッチング結果の図示 fit.m |&gt; summary() |&gt; plot(xlim = c(0,2)) マッチングしたデータを用いた推定 replacement無しの場合ｍマッチングしたペア(subclass)でクラスタリングしたrobust standard errorの利用を推奨 (Abadie and Spiess 2021) df &lt;- match.data(fit.m) # マッチング結果を含んだ lm_robust(log(wage) ~ occupation + education + south + smsa + gender + ethnicity + industry + weeks, df, clusters = subclass, weights = weights) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower ## (Intercept) 6.2462813341 0.183058784 34.1217242 7.558397e-47 5.881494177 ## occupationblue -0.1334544904 0.038580415 -3.4591253 6.683394e-04 -0.209553177 ## education 0.0544477095 0.007922490 6.8725504 3.319677e-10 0.038756725 ## southyes -0.0867718070 0.034560087 -2.5107520 1.286306e-02 -0.154932980 ## smsayes 0.1750365698 0.031398444 5.5746893 7.276141e-08 0.113153785 ## genderfemale -0.4412820442 0.039310364 -11.2255903 1.172494e-17 -0.519606156 ## ethnicityafam -0.2065702123 0.060934629 -3.3900299 1.422677e-03 -0.329149700 ## industryyes 0.1042406869 0.031857789 3.2720628 1.227905e-03 0.041477821 ## weeks 0.0001159795 0.003089531 0.0375395 9.702593e-01 -0.006146773 ## CI Upper DF ## (Intercept) 6.611068491 73.58037 ## occupationblue -0.057355804 190.88829 ## education 0.070138694 116.35533 ## southyes -0.018610634 194.25602 ## smsayes 0.236919355 218.36961 ## genderfemale -0.362957932 74.19948 ## ethnicityafam -0.083990725 47.07527 ## industryyes 0.167003553 235.35152 ## weeks 0.006378732 36.52184 References "],["general.html", "Chapter 4 平均差の推定 4.1 概念整理 4.2 パッケージ 4.3 データ 4.4 Robinsons推定 (SuperLearner) 4.5 Robinson推定 (DoubleML) 4.6 AIPW (AIPW)", " Chapter 4 平均差の推定 4.1 概念整理 条件付き平均差 \\(\\tau(x)=E[Y_i|D_i=d,X_i=x] - E[Y_i|D_i=d&#39;,X_i=x]\\) の特徴を推定 ここでは \\(\\tau = \\tau(x)\\) の平均値を推定 大きく２種類の推定方法を紹介 4.1.1 Robinson推定 部分線形モデル (Robinson 1988) 上で \\(\\tau\\) を定義 \\[E[Y|D=d,X=x]=\\underbrace{\\tau}_{Interest\\ parameter}\\times d+\\underbrace{f(x)}_{Nuisance\\ function}\\] 線形モデルの一般化として解釈できる: \\(f(X)=\\beta_0 + \\beta_1X_1+...+\\beta_LX_L\\) と定式化すれば線形モデルと一致 推定手順: 部分線形モデルを変換 \\[Y_i-\\underbrace{E[Y_i|X_i]}_{Nuisance\\ term}=\\tau\\times [D_i-\\underbrace{E[D_i|X_i]}_{Nuisance\\ term}]+u_i\\] \\(E[Y_i|X_i],E[D_i|X_i]\\)を予測関数として推定 予測誤差間を単回帰 実際には\\(E[Y_i|X_i],E[D_i|X_i]\\)は未知の関数なので何らかの方法で推定する必要がある。関数の推定なので予測の手法が適用できる。 4.1.2 Argument Inverse Propensity Score 2値の原因変数 \\(D_i=\\{0,1\\}\\) を想定 Double robust score (Robins and Rotnitzky 1995) \\(\\phi\\) を用いて推定 \\[\\phi_i(\\tilde \\mu_{1i},\\tilde \\mu_{0i},\\tilde \\mu_{Di})=\\tilde \\mu_{1i} - \\tilde \\mu_{0i} + \\frac{D_i\\times (Y_i-\\tilde \\mu_{1i})}{\\tilde \\mu_{Di}} + \\frac{(1-D_i)\\times (Y_i-\\tilde \\mu_{0i})}{1-\\tilde \\mu_{Di}}\\] 以下が成立 \\[\\tau\\equiv E[\\tau(x)]=E[\\phi_i(\\mu_{1i},\\mu_{0i},\\mu_{Di})]\\] ただし \\(\\mu_{1i}=E[Y_i|D_i=1,X_i]\\) , \\(\\mu_{0i}=E[Y_i|D_i=0,X_i]\\) , \\(\\mu_{Di}=E[D_i|X_i]\\) 推定手順 \\(\\mu_{1i},\\mu_{0i},\\mu_{Di}\\) を予測関数として推定 推定値 \\(\\tilde \\mu_{1i},\\tilde \\mu_{0i},\\tilde \\mu_{Di}\\) を用いて、 \\(\\phi_i(\\tilde \\mu_{1i},\\tilde \\mu_{0i},\\tilde \\mu_{Di})\\) を計算 \\(\\sum_i \\phi_i(\\tilde \\mu_{1i},\\tilde \\mu_{0i},\\tilde \\mu_{Di})/N\\) として \\(\\tau\\) を推定 4.2 パッケージ library(tidyverse) library(AER) library(DoubleML) library(mlr3) library(mlr3learners) library(data.table) library(SuperLearner) library(AIPW) library(SuperLearner) library(future.apply) library(recipes) library(estimatr) 4.3 データ data(&quot;PSID1982&quot;) set.seed(123) Y &lt;- PSID1982$wage |&gt; log() # 結果変数 D &lt;- if_else(PSID1982$occupation == &quot;white&quot;,1,0) X &lt;- recipe(~ education + south + smsa + gender + ethnicity + industry + weeks, PSID1982) |&gt; step_other(all_nominal_predictors(), other = &quot;others&quot;) |&gt; step_unknown(all_nominal_predictors()) |&gt; step_indicate_na(all_numeric_predictors()) |&gt; step_impute_median(all_numeric_predictors()) |&gt; step_dummy(all_nominal_predictors()) |&gt; step_zv(all_numeric_predictors()) |&gt; prep() |&gt; bake(PSID1982) 4.4 Robinsons推定 (SuperLearner) 部分線形モデルをDouble Machine Learning法 (Chernozhukov et al. 2018) で推定 なんらかの方法（例、OLS、ランダムフォレスト、LASSO）で\\(E[Y|X],E[D|X]\\)の予測関数\\(f_Y(X),f_D(X)\\)を推定し、予測誤差を単回帰 SuperLearner pakageを用いて推定 fit.Y &lt;- CV.SuperLearner(X = X, Y = Y, SL.library = c(&quot;SL.glmnet&quot;, &quot;SL.lm&quot;, &quot;SL.ranger&quot;) ) fit.D &lt;- CV.SuperLearner(X = X, Y = D, SL.library = c(&quot;SL.glmnet&quot;, &quot;SL.lm&quot;, &quot;SL.ranger&quot;) ) Y.oht &lt;- Y - fit.Y$SL.predict D.oht &lt;- D - fit.D$SL.predict lm_robust(Y.oht ~ 0 + D.oht) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF ## D.oht 0.1195776 0.03674064 3.254641 0.001199883 0.04742023 0.1917349 594 4.5 Robinson推定 (DoubleML) DoubleMLパッケージ(Bach et al. 2021)を利用 機械学習についてのメタパッケージである、mlr3がベース learner &lt;- lrn(&quot;regr.ranger&quot;, num.trees = 100) # Require bigger num.trees in practice ml_g &lt;- learner$clone() ml_m &lt;- learner$clone() obj_dml_data &lt;- double_ml_data_from_matrix(X = X, y = as.numeric(Y), d = as.numeric(D)) dml_plr_obj &lt;- DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, dml_procedure=&quot;dml1&quot;, n_rep = 3) dml_plr_obj$fit() ## INFO [15:31:46.341] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 3/5) ## INFO [15:31:46.386] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 5/5) ## INFO [15:31:46.413] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 2/5) ## INFO [15:31:46.434] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 1/5) ## INFO [15:31:46.455] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 4/5) ## INFO [15:31:46.525] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 1/5) ## INFO [15:31:46.546] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 2/5) ## INFO [15:31:46.566] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 4/5) ## INFO [15:31:46.588] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 5/5) ## INFO [15:31:46.610] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 3/5) ## INFO [15:31:46.690] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 2/5) ## INFO [15:31:46.714] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 5/5) ## INFO [15:31:46.738] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 3/5) ## INFO [15:31:46.762] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 4/5) ## INFO [15:31:46.787] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 1/5) ## INFO [15:31:46.851] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 3/5) ## INFO [15:31:46.872] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 4/5) ## INFO [15:31:46.893] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 1/5) ## INFO [15:31:46.913] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 5/5) ## INFO [15:31:46.933] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 2/5) ## INFO [15:31:47.001] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 5/5) ## INFO [15:31:47.024] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 3/5) ## INFO [15:31:47.050] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 2/5) ## INFO [15:31:47.072] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 4/5) ## INFO [15:31:47.093] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_g&#39; (iter 1/5) ## INFO [15:31:47.150] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 4/5) ## INFO [15:31:47.170] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 5/5) ## INFO [15:31:47.191] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 1/5) ## INFO [15:31:47.213] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 2/5) ## INFO [15:31:47.233] [mlr3] Applying learner &#39;regr.ranger&#39; on task &#39;nuis_m&#39; (iter 3/5) print(dml_plr_obj) ## ================= DoubleMLPLR Object ================== ## ## ## ------------------ Data summary ------------------ ## Outcome variable: y ## Treatment variable(s): d ## Covariates: X1, X2, X3, X4, X5, X6, X7 ## Instrument(s): ## No. Observations: 595 ## ## ------------------ Score &amp; algorithm ------------------ ## Score function: partialling out ## DML algorithm: dml1 ## ## ------------------ Machine learner ------------------ ## ml_g: regr.ranger ## ml_m: regr.ranger ## ## ------------------ Resampling ------------------ ## No. folds: 5 ## No. repeated sample splits: 3 ## Apply cross-fitting: TRUE ## ## ------------------ Fit summary ------------------ ## Estimates and significance testing of the effect of target variables ## Estimate. Std. Error t value Pr(&gt;|t|) ## d 0.13122 0.03619 3.625 0.000289 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.6 AIPW (AIPW) AIPWパッケージを用いて、AIPW推定 SuperLearnerパッケージがベース plan(multisession, workers = 8, gc = T) algorism &lt;- AIPW$new( Y = Y, A = D, W = X, Q.SL.library = c( &quot;SL.lm&quot;, &quot;SL.ranger&quot;, &quot;SL.glmnet&quot; ), g.SL.library = c( &quot;SL.lm&quot;, &quot;SL.ranger&quot;, &quot;SL.glmnet&quot; ) ) algorism$stratified_fit()$summary() ## Estimate SE 95% LCL 95% UCL N ## Risk of exposure 6.9744 0.0502 6.8760 7.073 290 ## Risk of control 6.8572 0.0189 6.8202 6.894 305 ## Risk Difference 0.1171 0.0515 0.0162 0.218 595 ## ATT Risk Difference 0.1926 0.0280 0.1377 0.248 595 ## ATC Risk Difference 0.0402 0.0943 -0.1447 0.225 595 4.6.1 Balance check 0あるいは1に非常に近い \\(\\tilde\\mu_{Di}\\) が存在する場合、AIPW推定は極めて不安定 Default設定では, \\(\\tilde \\mu_{Di} \\le 0.025\\) または \\(\\tilde \\mu_{Di} \\ge 0.975\\) であればサンプル \\(i\\) は推定から排除される 平均差の推定の前に、 \\(\\tilde\\mu_{Di}\\) の分布を確認する必要がある \\(\\tilde\\mu_{Di}\\) の分布 algorism$plot.p_score() References "],["hetero.html", "Chapter 5 条件付き平均効果関数の推定 5.1 問題設定 5.2 パッケージ 5.3 データ 5.4 Casual Forest 5.5 Best linear predictors 5.6 Distribution of predicted individual effects", " Chapter 5 条件付き平均効果関数の推定 5.1 問題設定 条件付き平均差関数 \\(\\tau(d,d&#39;,x)=E[Y_i|D_i=d,X_i=x]-E[Y_i|D_i=d&#39;,X_i=x]\\) を推定 大きく２種類の推定戦略を紹介 パラメトリック な近似モデル: \\(\\tau(d,d&#39;,z)\\) の有限のパラメータからなる近似モデルを推定 前章の周辺化平均もこの一種: \\(\\tau(d,d&#39;,x) \\approx \\beta\\) として近似 線形モデル \\(\\tau(d,d&#39;,x) \\approx \\beta_0 + \\beta_1X_1+...+\\beta_LX_L\\) で近似 どちらの場合であっても信頼区間を計算可能 ノンパラメトリック モデル: 教師付き学習によりノンパラメトリックに推定 一般に信頼区間の計算が困難 Causal Forest algorismは例外的に漸近正規性に基づく信頼区間の近似計算を提供 5.2 パッケージ library(tidyverse) library(AER) library(recipes) library(grf) library(rpart) library(rpart.plot) 5.3 データ data(&quot;PSID1982&quot;) set.seed(123) Y &lt;- PSID1982$wage |&gt; log() # 結果変数 D &lt;- if_else(PSID1982$occupation == &quot;white&quot;,1,0) X &lt;- recipe(~ education + south + smsa + gender + ethnicity + industry + weeks, PSID1982) |&gt; step_other(all_nominal_predictors(), other = &quot;others&quot;) |&gt; step_unknown(all_nominal_predictors()) |&gt; step_indicate_na(all_numeric_predictors()) |&gt; step_impute_median(all_numeric_predictors()) |&gt; step_dummy(all_nominal_predictors()) |&gt; step_zv(all_numeric_predictors()) |&gt; prep() |&gt; bake(PSID1982) X &lt;- as.matrix(X) set.seed(123) 5.4 Casual Forest Causal Forest (Wager and Athey 2018; Athey et al. 2019) を基盤とした推定方法を紹介 \\(\\tau(X)\\) は以下の一般化された部分線形モデルで定義 \\[E[Y|D,X]=\\tau(X)\\times D + f(X)\\] Random Forest をベースに \\(\\tau(X)\\) の近似関数を推定 fit &lt;- regression_forest(X = X, Y = Y) Y.hat &lt;- predict(fit)$predictions fit &lt;- regression_forest(X = X, Y = D) D.hat &lt;- predict(fit)$predictions fit.CF &lt;- causal_forest(X = X, W = D, Y = Y, Y.hat = Y.hat, W.hat = D.hat, num.trees = 4000 ) 5.5 Best linear predictors 線形近似モデル \\(\\tau(x)\\approx \\beta_0 + \\beta_1X_1+...+\\beta_LX_L\\) を推定 \\(X\\) はscale関数によって標準化 \\(\\beta_0\\) を”平均効果”として解釈可能 best_linear_projection(fit.CF,scale(X)) ## ## Best linear projection of the conditional average treatment effect. ## Confidence intervals are cluster- and heteroskedasticity-robust (HC3): ## ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.19596292 0.07019857 2.7916 0.005416 ** ## education 0.08618803 0.07001161 1.2311 0.218796 ## weeks 0.06479440 0.05452998 1.1882 0.235222 ## south_yes -0.05390008 0.05280003 -1.0208 0.307753 ## smsa_yes -0.06226340 0.06482436 -0.9605 0.337202 ## gender_female 0.00019173 0.03808792 0.0050 0.995985 ## ethnicity_afam -0.06304902 0.04463958 -1.4124 0.158362 ## industry_yes -0.07646084 0.06049545 -1.2639 0.206764 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 5.6 Distribution of predicted individual effects 一般にノンパラメトリック モデルでは、信頼区間計算が難しい \\(X\\) の数が少ないCausal forestでは “例外”的に計算可能 df &lt;- mutate(PSID1982, tau = predict(fit.CF, estimate.variance = TRUE)$predictions, sd = predict(fit.CF, estimate.variance = TRUE)$variance.estimates |&gt; sqrt()) df |&gt; arrange(tau) |&gt; ggplot(aes(x = c(1:nrow(df)), y = tau, ymin = tau - 1.96*sd, ymax = tau + 1.96*sd) ) + geom_ribbon(alpha = 0.8) + geom_line() + geom_hline(yintercept = 0) + theme_bw() References "],["panel.html", "Chapter 6 Panel data 6.1 パッケージ 6.2 Data 6.3 識別: Pallarel trend in the two-by-two case 6.4 推定: Two-way fixed effect model 6.5 推定:Weighted two-way fixed effect model", " Chapter 6 Panel data \\(\\{Y_{it},D_{it},X_{it}\\}\\)が観察できるデータを想定する \\(i:\\)回答者、\\(t:\\)回答時点 6.1 パッケージ library(tidyverse) library(estimatr) library(AER) library(did) # weighted two-way fixed effect 6.2 Data AERパッケージに含まれるパネルデータPSID7682を利用 595名の回答者について、1976年から1983年までの7期間パネルデータ data(&quot;PSID7682&quot;) data &lt;- PSID7682 |&gt; group_by(id) |&gt; mutate(period = as.numeric(year), # yearを連続変数化 treatment.time = if_else(married == &quot;yes&quot;, period, 999), treatment.time = min(treatment.time) ) |&gt; # 結婚したperiodを作成(結婚しなかったサンプル = 9999) ungroup() 6.3 識別: Pallarel trend in the two-by-two case 2時点・2グループデータ トリートメントグループ: 2期目に介入を受ける コントロールグループ: 両期間ともに介入を受けない Pallalel trendの仮定 \\(E[Y_{2i}(0)-Y_{1i}(0)|i\\in Treatment]-E[Y_{2i}(0)-Y_{1i}(0)|i\\in Control]\\) 差の差の推定量を推定 \\[E[Y_{i2}|i\\in Treatment]-E[Y_{i1}|i \\in Treatment]\\] \\[-(E[Y_{i2}|i\\in Control]-E[Y_{i1}|i \\in Control])\\] \\[= E[Y_{i2}(1) - Y_{i2}(0)|i \\in Treatment]\\] 6.4 推定: Two-way fixed effect model Two-way fixed effect model \\[E[Y_{it}|D_{it}=d,f_{i},f_{t}]=\\beta_\\tau\\times d + f_i + f_t\\] Two-by-two dataのもとでは、差の差の推定と同値 Two-by-two dataの整備 df &lt;- data |&gt; filter(period &lt;= 2) |&gt; # 1,2期目データ filter(treatment.time == 999 | treatment.time == 2) |&gt; # トリートメント/コントロールグループ mutate(D = if_else(period &gt;= treatment.time, 1, 0) ) # 介入後ダミー Two-way fixed effectの推定 lm_robust(weeks ~ D + factor(period), data = df, clusters = id, fixed_effects = id) ## Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper ## D -1.066667 1.2271177 -0.8692456 0.4713004 -6.0381262 3.904793 ## factor(period)2 1.400000 0.8532526 1.6407803 0.1043726 -0.2953947 3.095395 ## DF ## D 2.135502 ## factor(period)2 89.000000 6.5 推定:Weighted two-way fixed effect model 2期間以上のデータにおいて、parallel trendの仮定に基づいて因果効果を推定する手法 ここでは Callaway and Sant’Anna (2020) を紹介 データ整備 df &lt;- data |&gt; filter(treatment.time != 1) |&gt; mutate(id = as.numeric(id), treatment.time = if_else(treatment.time == 999, 0, treatment.time) ) 推計 fit &lt;- att_gt(yname = &quot;weeks&quot;, tname = &quot;period&quot;, idname = &quot;id&quot;, gname = &quot;treatment.time&quot;, data = df, control_group = 999) fit ## ## Call: ## att_gt(yname = &quot;weeks&quot;, tname = &quot;period&quot;, idname = &quot;id&quot;, gname = &quot;treatment.time&quot;, ## data = df, control_group = 999) ## ## Reference: Callaway, Brantly and Pedro H.C. Sant&#39;Anna. &quot;Difference-in-Differences with Multiple Time Periods.&quot; Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; ## ## Group-Time Average Treatment Effects: ## Group Time ATT(g,t) Std. Error [95% Simult. Conf. Band] ## 2 2 -0.9412 1.1090 -3.8502 1.9678 ## 2 3 -2.5455 2.4102 -8.8679 3.7769 ## 2 4 -8.8526 7.6182 -28.8366 11.1314 ## 2 5 -8.2151 9.1243 -32.1498 15.7197 ## 2 6 -1.5055 1.2416 -4.7623 1.7514 ## 2 7 -2.2556 1.9195 -7.2908 2.7797 ## 3 2 -2.3434 0.9547 -4.8477 0.1608 ## 3 3 1.7980 0.7098 -0.0639 3.6598 ## 3 4 0.7228 1.3343 -2.7773 4.2229 ## 3 5 1.0538 0.8148 -1.0835 3.1910 ## 3 6 0.2125 1.2731 -3.1271 3.5520 ## 3 7 1.8111 1.7658 -2.8208 6.4430 ## 4 2 2.5765 5.1357 -10.8955 16.0486 ## 4 3 0.6579 2.0509 -4.7220 6.0378 ## 4 4 -2.7684 1.2410 -6.0238 0.4869 ## 4 5 -1.0860 1.8611 -5.9680 3.7960 ## 4 6 -6.8489 8.2446 -28.4761 14.7783 ## 4 7 0.5833 1.0872 -2.2687 3.4354 ## 5 2 -1.3000 0.7710 -3.3224 0.7224 ## 5 3 -0.8866 0.9598 -3.4043 1.6311 ## 5 4 -0.2742 0.6540 -1.9898 1.4414 ## 5 5 -0.3118 0.8957 -2.6613 2.0377 ## 5 6 -3.4286 3.4714 -12.5348 5.6777 ## 5 7 0.5222 0.6690 -1.2327 2.2771 ## 6 2 -5.3800 2.6992 -12.4606 1.7006 ## 6 3 -7.5206 8.0760 -28.7055 13.6643 ## 6 4 4.8333 5.2688 -8.9878 18.6545 ## 6 5 6.3242 5.4700 -8.0247 20.6731 ## 6 6 -6.2527 2.7701 -13.5191 1.0136 ## 6 7 -2.3222 1.0107 -4.9736 0.3291 ## 7 2 -1.2871 0.7614 -3.2845 0.7103 ## 7 3 0.1327 0.6607 -1.6005 1.8658 ## 7 4 -1.7872 0.5631 -3.2644 -0.3101 * ## 7 5 1.7065 0.4957 0.4062 3.0069 * ## 7 6 -2.2778 0.6351 -3.9439 -0.6117 * ## 7 7 0.9556 0.5356 -0.4493 2.3605 ## --- ## Signif. codes: `*&#39; confidence band does not cover 0 ## ## P-value for pre-test of parallel trends assumption: 0 ## Control Group: , Anticipation Periods: 0 ## Estimation Method: Doubly Robust 単純平均効果 fit |&gt; aggte(type = &quot;simple&quot;) |&gt; summary() ## ## Call: ## aggte(MP = fit, type = &quot;simple&quot;) ## ## Reference: Callaway, Brantly and Pedro H.C. Sant&#39;Anna. &quot;Difference-in-Differences with Multiple Time Periods.&quot; Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; ## ## ## ATT Std. Error [ 95% Conf. Int.] ## -1.9877 1.1326 -4.2077 0.2322 ## ## ## --- ## Signif. codes: `*&#39; confidence band does not cover 0 ## ## Control Group: , Anticipation Periods: 0 ## Estimation Method: Doubly Robust 動学効果 fit |&gt; aggte(type = &quot;dynamic&quot;) |&gt; ggdid() References "],["RD.html", "Chapter 7 Regression-discontinuity 7.1 問題意識 7.2 パッケージ &amp; データ 7.3 Shap disconiniuity", " Chapter 7 Regression-discontinuity Regression discontinuityに基づく推定方法を紹介 Chapter 7.1 : Regression discontinuityにおける問題意識を紹介 Chapter 7.3 : Sharp designに基づく推定方法を紹介 7.1 問題意識 識別の仮定：ある変数\\(X\\)について、以下の条件を満たすcutoff \\(c\\)が存在する \\(\\lim_{x\\uparrow c}\\Pr[D_i=d|X=x]\\neq \\lim_{x\\downarrow c}\\Pr[D_i=d|X=x]\\): 原因変数の分布がcutoffの前後で非連続的に変化している 通常、Cutoffの近傍には少数のサンプルしかないので、外挿する必要がある。 Local polynomial regressionによる局所的外挿は、rdrobustパッケージ (Calonico et al. 2021)により実装できる。 同パッケージによる実装も含んだ包括的な入門は Cattaneo, Idrobo, and Titiunik (2019b), Cattaneo, Idrobo, and Titiunik (2019a). 7.2 パッケージ &amp; データ Rdrobustに同梱されれいるExample data (Cattaneo, Frandsen, and Titiunik 2015)を使用 選挙における現職効果（現在議席を得ている候補者のほうが選挙で有利になる）を推定 running variable \\(=\\) margin (前回の選挙におけるライバル政党との得票率差) cutoff \\(=\\) 0 (差がない) outcome variable \\(=\\) vote (選挙における得票率) library(rdrobust) library(tidyverse) data(&quot;rdrobust_RDsenate&quot;) raw &lt;- rdrobust_RDsenate 7.3 Shap disconiniuity 推計前に\\(X\\)と\\(Y\\)についての散布図を確認することを推奨 raw |&gt; ggplot(aes(x = margin, y = vote) ) + geom_point() + geom_vline(xintercept = 0) 初期設定では2nd oder local polynominalを利用 (Gelman and Imbens (2019) の推奨) Y &lt;- raw$vote X &lt;- raw$margin rdplot(y = Y, x = X) 推定結果表 + 標準誤差 rdrobust(y = Y, x = X) |&gt; summary() ## Call: rdrobust ## ## Number of Obs. 1297 ## BW type mserd ## Kernel Triangular ## VCE method NN ## ## Number of Obs. 595 702 ## Eff. Number of Obs. 360 323 ## Order est. (p) 1 1 ## Order bias (q) 2 2 ## BW est. (h) 17.754 17.754 ## BW bias (b) 28.028 28.028 ## rho (h/b) 0.633 0.633 ## Unique Obs. 595 665 ## ## ============================================================================= ## Method Coef. Std. Err. z P&gt;|z| [ 95% C.I. ] ## ============================================================================= ## Conventional 7.414 1.459 5.083 0.000 [4.555 , 10.273] ## Robust - - 4.311 0.000 [4.094 , 10.919] ## ============================================================================= References "],["pipe.html", "Chapter 8 パイプ演算子", " Chapter 8 パイプ演算子 R version 4.1からpipe演算子が、追加パッケージなしで利用可能になった Tools -&gt; Global option -&gt; Code -&gt; “Use native pipe operator” をチェックする Ctr + Shift + mがショートカット 現状、magrittrパッケージが提供するpipe (%&gt;%)に比べて、機能が限定されている pipe演算子：二つの入力X1,X2から出力Yを得る関数fについて、pipe演算子を用いると、Y &lt;- X1 |&gt; f(X2)と書き換えられる pipe演算子を使わない場合、ある出力結果を入力として用いるためには、複数のobjectを作成する必要があり煩雑 n &lt;- rnorm(100) # 標準正規分布から100個値を取得し、nと名付ける hist(n) # nを用いてヒストグラムを描画 pipe演算子を使うと以下のようになる rnorm(100) |&gt; hist() "],["データ整備.html", "Chapter 9 データ整備 9.1 パッケージ &amp; データ 9.2 新しい変数の作成 9.3 変数の限定 9.4 サンプルの除外 9.5 記述統計表の作成", " Chapter 9 データ整備 Chapter 9.2-9.4 : tidyverseに同梱されるdplyrパッケージに含まれる関数を用いた、データの加工法を紹介 Chapter 9.5 : gtsummaryパッケージ(Sjoberg et al. 2022)を用いた記述統計表を作成 9.1 パッケージ &amp; データ library(tidyverse) # データ整備 library(AER) # Example データ library(gtsummary) # 記述統計量 data(&quot;NMES1988&quot;) ## データの取得 raw &lt;- NMES1988 ## rawという名前に変更 9.2 新しい変数の作成 mutate関数の利用 df &lt;- raw |&gt; mutate(age_2 = age^2) # 年齢の二乗項を作成 9.3 変数の限定 select関数の利用 df &lt;- raw |&gt; select(age, income) 特定の変数の除外 df &lt;- raw |&gt; select(-age, -income) 9.4 サンプルの除外 filter関数の利用 df &lt;- raw |&gt; filter(visits &gt;= 7) 9.5 記述統計表の作成 記述統計の作成には多くの有益なパッケージが存在 ここではgtsummaryを使用 select関数で必要な変数(visits, health, medicaid)を抜き出し、insuranceごとに連続変数については中央値、カテゴリ変数については頻度を記述 raw |&gt; # rawを入力とし select(visits, health, medicaid, insurance ) |&gt; # 必要な変数を抜き出す tbl_summary(by = insurance) # 記述統計を計算 html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #pjvqvywttq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #pjvqvywttq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #pjvqvywttq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #pjvqvywttq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #pjvqvywttq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #pjvqvywttq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #pjvqvywttq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #pjvqvywttq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #pjvqvywttq .gt_column_spanner_outer:first-child { padding-left: 0; } #pjvqvywttq .gt_column_spanner_outer:last-child { padding-right: 0; } #pjvqvywttq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #pjvqvywttq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #pjvqvywttq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #pjvqvywttq .gt_from_md > :first-child { margin-top: 0; } #pjvqvywttq .gt_from_md > :last-child { margin-bottom: 0; } #pjvqvywttq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #pjvqvywttq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #pjvqvywttq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #pjvqvywttq .gt_row_group_first td { border-top-width: 2px; } #pjvqvywttq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #pjvqvywttq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #pjvqvywttq .gt_first_summary_row.thick { border-top-width: 2px; } #pjvqvywttq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #pjvqvywttq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #pjvqvywttq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #pjvqvywttq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #pjvqvywttq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #pjvqvywttq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #pjvqvywttq .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #pjvqvywttq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #pjvqvywttq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #pjvqvywttq .gt_left { text-align: left; } #pjvqvywttq .gt_center { text-align: center; } #pjvqvywttq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #pjvqvywttq .gt_font_normal { font-weight: normal; } #pjvqvywttq .gt_font_bold { font-weight: bold; } #pjvqvywttq .gt_font_italic { font-style: italic; } #pjvqvywttq .gt_super { font-size: 65%; } #pjvqvywttq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #pjvqvywttq .gt_asterisk { font-size: 100%; vertical-align: 0; } #pjvqvywttq .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #pjvqvywttq .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #pjvqvywttq .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } Characteristic no, N = 9851 yes, N = 3,4211 visits 3 (1, 7) 4 (2, 8) health poor 204 (21%) 350 (10%) average 721 (73%) 2,788 (81%) excellent 60 (6.1%) 283 (8.3%) medicaid 341 (35%) 61 (1.8%) 1 Median (IQR); n (%) 連続変数について、平均値と標準偏差を記述 raw |&gt; select(visits, health, medicaid, insurance ) |&gt; tbl_summary(by = insurance, statistic = list(all_continuous() ~ &quot;{mean} ({sd})&quot;) # 平均と標準誤差を表示 ) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #lmvmutznoq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lmvmutznoq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lmvmutznoq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lmvmutznoq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #lmvmutznoq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lmvmutznoq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lmvmutznoq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lmvmutznoq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lmvmutznoq .gt_column_spanner_outer:first-child { padding-left: 0; } #lmvmutznoq .gt_column_spanner_outer:last-child { padding-right: 0; } #lmvmutznoq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #lmvmutznoq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #lmvmutznoq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lmvmutznoq .gt_from_md > :first-child { margin-top: 0; } #lmvmutznoq .gt_from_md > :last-child { margin-bottom: 0; } #lmvmutznoq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lmvmutznoq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #lmvmutznoq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #lmvmutznoq .gt_row_group_first td { border-top-width: 2px; } #lmvmutznoq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lmvmutznoq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #lmvmutznoq .gt_first_summary_row.thick { border-top-width: 2px; } #lmvmutznoq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lmvmutznoq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lmvmutznoq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lmvmutznoq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lmvmutznoq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lmvmutznoq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lmvmutznoq .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #lmvmutznoq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lmvmutznoq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lmvmutznoq .gt_left { text-align: left; } #lmvmutznoq .gt_center { text-align: center; } #lmvmutznoq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lmvmutznoq .gt_font_normal { font-weight: normal; } #lmvmutznoq .gt_font_bold { font-weight: bold; } #lmvmutznoq .gt_font_italic { font-style: italic; } #lmvmutznoq .gt_super { font-size: 65%; } #lmvmutznoq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #lmvmutznoq .gt_asterisk { font-size: 100%; vertical-align: 0; } #lmvmutznoq .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #lmvmutznoq .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #lmvmutznoq .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } Characteristic no, N = 9851 yes, N = 3,4211 visits 5 (6) 6 (7) health poor 204 (21%) 350 (10%) average 721 (73%) 2,788 (81%) excellent 60 (6.1%) 283 (8.3%) medicaid 341 (35%) 61 (1.8%) 1 Mean (SD); n (%) References "],["可視化.html", "Chapter 10 可視化 10.1 パッケージ &amp; データ 10.2 連続-カテゴリのケース 10.3 連続-連続のケース", " Chapter 10 可視化 議論の出発点として、データ内におけるY/X間の関係性を整理・記述することが重要 最有力な手法は可視化 tidyverseに含まれるggplot2パッケージ(Wickham et al. 2021)を利用し、可視化 Chapter 10.2 : Yが連続変数、Xがカテゴリー変数のケースについて有効なヒストグラム、密度関数、boxplotを描写 Chapter 10.3 :Xも連続変数のケースについて有効な散布図、ヒートマップを描写 10.1 パッケージ &amp; データ library(tidyverse) # 可視化 library(AER) # 例データ data(&quot;NMES1988&quot;) # データの取り込み raw &lt;- NMES1988 # 名前変更 変数のタイプに応じて、変数間の関係性を記述するために有効な図は異なる。 ここでは、Y/Xが共に連続(連続-連続)のケース、Xがカテゴリカル(連続-カテゴリ)なケースについて、代表的な図を紹介する 10.2 連続-カテゴリのケース 10.2.1 ヒストグラム 医療機関の利用回数 raw |&gt; ggplot(aes(x = visits)) + geom_histogram() 保険の有無別 raw |&gt; ggplot(aes(x = visits, fill = insurance) ) + geom_histogram(position = &quot;identity&quot;, alpha = 0.5) 10.2.2 密度 保険の有無別分布 raw |&gt; ggplot(aes(x = visits, fill = insurance) ) + geom_density(position = &quot;identity&quot;, alpha = 0.5) 10.2.3 Boxplot raw |&gt; ggplot(aes(y = visits, x = insurance) ) + geom_boxplot() 10.3 連続-連続のケース 10.3.1 散布図 散布図：連続変数間の関係性を可視化する図 raw |&gt; ggplot(aes(x = age, y = visits) ) + geom_point() サンプルサイズが大きくなると機能しない 10.3.2 ヒートマップ 代替案はヒートマップ raw |&gt; ggplot(aes(x = age, y = visits) ) + geom_bin2d() References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
