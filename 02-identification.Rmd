# 目標

- 経済学におけるデータ分析の大部分は、複数の変数間での関係性の理解・利用を目的とします。

- ここではある結果変数$Y$と独立変数（群）$X=X_1,...,X_L$の関係性に焦点を当てます。

- より具体的な目標は大きく（予測）$Y$の予測関数の推定、（比較）異なる$X$間での$Y$の比較、（因果効果）$X$の変化が$Y$に与える因果効果の推定、に大別できます。

- $Y$と$X$がともに観察でき、関心のある母集団からランダムサンプリングされたデータが入手出来ているとします。

## 予測

- Chapter \@ref(prediction) の背後にある問題意識・方針を紹介します。

### 問題設定

- データと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測することを目的とします。

- 具体的には、事前に定義する損失関数の期待値を最小化するような、予測関数$f(X)$の推定をめざします。
以下ではMean squared error(MSE)を損失関数として用います。
所与の$f(X)$、母分布に従う確率変数$Y,X$についてMSEは以下のように定義されます。

$$MSE = E_{X,Y}[(Y_i-f(X_i))^2]$$

- 一般にMSEは以下のように書き換えられます。

$$MSE = \underbrace{E_{X,Y}[(Y_i-\bar{Y}(X_i))^2]}_{Irreducible\ error}+\underbrace{E_{X,Y}[(\bar{Y}(X_i)-f(X_i))^2]}_{Reducible\ error}$$
ただし$\bar{Y}(X_i)=E[Y_i|X_i]$。
上記式から以下が確認できます。

  - 最善の予測関数は条件付き母平均$\bar{Y}(X_i)$(Reducible error = 0)
  
  - 最善の予測関数のもとでも削減不可能なエラー(Irreducible error)が存在
  
  - 予測関数の推定 $=$ Reducible errorの削減 $=$ 条件付き母平均との乖離(MSE)の削減

### Bias-Variance tradeoff

- 実際の$f(X_i)$はランダムサンプリングされたデータから推定される必要があり、実際には確率分布を持ちます。

- Reducible errorは一般に以下のように書き換えられます。

$$E_{Y,X,f(X)}[(\bar{Y}(X_i)-f(X_i))^2]$$

$$=\underbrace{(E_{Y,X,f(X)}[\bar{Y}(X_i)-\bar{f}(X_i)])^2}_{Bias}+\underbrace{E_{Y,X,f(X)}[(\bar{f}(X_i)-f(X_i))^2]}_{Variance}.$$
ただし$\bar{f}(X_i)=f(X_i)$。

- 上記式は推定される予測関数が平均的にどの程度条件付き母平均を近似できているのか(Biasがどの程度小さいのか)だけでなく、予測関数の分布がどの程度散らばっているのか（VArianceがどの程度大木のか）、についても考慮する必要があることを示しています。

- 母平均$\bar Y(X_i)$が単純な既知の関数形に従い、かつサンプルサイズが大きい場合、OLS推定された$f(X_i)$は$Bias=0$かつ小さいVarianceを達成します。
しかしながら社会科学における多くの応用においては、$\bar Y(X_i)$は未知かつ複雑であることが予想され、その複雑さに対してサンプルサイズが小さいことを想定する必要があります。
このような状況では、OLSやサブサンプル平均により推定された予測モデルは、Bias-Variance tradeoffに直面します。

  - 少ないパラメータ（短い回帰式、少ないサブサンプル分割）を推定する場合、大きなBiasを持つ
  
  - 多くのパラメータ（長い回帰式、多いサブサンプル分割）を推定する場合、大きなVarianceを持つ。

- Bias-variance tradeoffを分析者が解くこと（最善のモデル設定を行うこと）は困難です。Chapter \@ref(prediction) で紹介するLASSO/Ridge/Random Forestなどの手法は、bias-varianceのバランスをよりデータ主導型かつ現実的な計算時間で達成することを目指します。

## 比較

- Chapter \@ref(unique) の背後にある問題意識・方針を紹介します。

### 問題設定

- 変数$D$の値が異なる集団間において、結果変数$Y$の分布がどの程度異なっているのか、推定します。
その際直接的な関心ではない変数群$X$は一定であるとします。

- 以下の議論では$Y$の平均値に焦点を当て、$E[Y|D=d,X]-E[Y|D=d',X]$の推定を目指します。
またこの際に点推定量のみならず、信頼区間の推定も行います。

### High-dimentional X

- 多数の$X$で条件づける必要がある場合、重回帰やマッチング法などの手法の有効性が失われます。
これは予測で問題となった大きすぎるvarianceが生じてしまうためです。

- なお$X$が少数であったとしても、定式化の自由度（高次項や交差項の導入）を持たせた場合、同様の問題が生じます。

- この問題を回避するためにChapter \@ref(unique) では、LASSOやRandom Forestなどの予測手法の応用を紹介します。

## 因果効果

- 引き続きChapter \@ref(unique) の背後にある問題意識・方針を紹介します。

### 問題設定

- ある集団の変数$D$を変化させた場合、結果変数$Y$の分布がどのように変化するのか、因果効果を推定します。

### 識別の問題

- 因果効果を推定する際には、識別条件をまず議論する必要があります。

  - 識別条件：「仮にサンプルサイズが無限大である」場合、どのような仮定の下で因果効果を推定できるか？
  
- 本ページでは$D$の条件付きランダム化（$X$が均一のグループ内では、$D$の値がランダムに決定されている）の仮定に基づき議論していきます。
この仮定のもとで$D$の因果効果は、$E[Y|D=d,X]-E[Y|D=d',X]$によって識別できます。

- 代替的な識別条件も複数存在

### 推定の問題

- 識別条件はしばしば多数の$X$について、条件づけた平均差の推定を要求されます
このような状況では比較の問題と同様に、機械学習の応用が有益となります。





