# 問題意識

- 経済学におけるデータ分析の大部分は、複数の変数間での関係性の理解・利用を目的とします。

- ここではある結果変数$Y$と独立変数（群）$X=X_1,...,X_L$の関係性に焦点を当てます。

- より具体的な目標は大きく（予測）$Y$の予測関数の推定、（比較）異なる$X$間での$Y$の比較、（因果効果）$X$の変化が$Y$に与える因果効果の推定、に大別できます。

- $Y$と$X$がともに観察でき、関心のある母集団からランダムサンプリングされたデータが入手出来ているとします。

## 予測

- Chapter \@ref(prediction) の背後にある問題意識・方針を紹介します。

- 問題設定：データと同じ母集団から新しくランダムサンプリングされ、$X$のみが観察できるサンプルについて$Y$の値を予測します。

### 損失関数

具体的には、事前に定義する損失関数の期待値を最小化するような、予測関数$f(X)$の推定をめざします。
以下ではMean squared errorを損失関数として用います。
所与の$f(X)$、母分布に従う確率変数$Y,X$についてMSEは以下のように定義されます。

$$MSE = E_{X,Y}[(Y_i-f(X_i))^2]$$

- 一般にMSEは以下のように書き換えられます。

$$MSE = \underbrace{E_{X,Y}[(Y_i-\bar{Y}(X_i))^2]}_{Irreducible\ error}+\underbrace{E_{X,Y}[(\bar{Y}(X_i)-f(X_i))^2]}_{Reducible\ error}$$
ただし$\bar{Y}(X_i)=E[Y_i|X_i]$。
上記式から

  - 最善の予測関数は条件付き母平均$\bar{Y}(X_i)$
  
  - 最善の予測関数のもとでも削減不可能なエラー(Irreducible error)が存在
  
  - 予測関数の推定 $=$ Reducible errorの削減 $=$ 条件付き母平均との乖離(MSE)の削減

### Bias-Variance tradeoff

- 実際の$f(X_i)$はランダムサンプリングされたデータから推定される必要があり、実際には確率的に決定される。

- Reducible errorは一般に以下のように書き換えられる。

$$E_{Y,X,f(X)}[(\bar{Y}(X_i)-f(X_i))^2]$$

$$=\underbrace{(E_{Y,X,f(X)}[\bar{Y}(X_i)-\bar{f}(X_i)])^2}_{Bias}+\underbrace{E_{Y,X,f(X)}[(\bar{f}(X_i)-f(X_i))^2]}_{Variance}.$$
ただし$\bar{f}(X_i)=f(X_i)$。

- 母平均$\bar Y(X_i)$が単純な既知の関数形に従い、かつサンプルサイズが大きい場合、OLS推定された$f(X_i)$は$Bias=0$かつ小さいVarianceを達成する。

- 社会科学における応用においては、$\bar Y(X_i)$は未知かつ複雑であることが想定され、その複雑さに対してサンプルサイズが小さいことが想定される。

- OLSやサブサンプル平均により推定された予測モデルは、Bias-Variance tradeoffに直面する

  - 少ないパラメータ（短い回帰式、少ないサブサンプル分割）を推定する場合、大きなBiasを持つ
  
  - 多くのパラメータ（長い回帰式、多いサブサンプル分割）を推定する場合、大きなVarianceを持つ。

- Bias-variance tradeoffを分析者が解くこと（最善のモデル設定を行うこと）は困難

- Chapter \@ref(prediction) で紹介するLASSO/Ridge/Random Forestなどの手法は、よりデータ主導型のアプローチを現実的な計算時間で行う。

## 比較

- Chapter \@ref(unique) の背後にある問題意識・方針を紹介します。

## 因果効果

- Chapter \@ref(unique) の背後にある問題意識・方針を紹介します。

