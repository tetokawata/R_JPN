
# 部分線形モデルの推定 {#unique}

- （条件付き）平均差の周辺化値の推定を目指します。

- モデルに関心のあるパラメータを埋め込み、推定します。

$$E[Y|D=d,X=x]=\underbrace{\tau}_{Interest\ parameter}\times d+\underbrace{f(x)}_{Nuisance\ function}$$

- 点推定だけでなく、信頼区間も推定する。

## データ

```{r}
library(tidyverse)

data("NMES1988",
     package = "AER")

raw <- na.omit(NMES1988)

set.seed(123)
```

## 線形モデルの推定


- $\tau(x)=\tau,f(x)=\beta_0+\beta_1x_1+...+\beta_Lx_L$と特定化

- サンプル内MSEを最大化するように推定

- robust standard errorを計算するためにestimatrパッケージ[@R-estimatr]を利用

```{r}
library(estimatr)
```

- lm_robust関数で推定

```{r}
lm_robust(visits ~ insurance + region + age + afam + gender + school,
          data = raw)
```

- 線形モデルによる推定は、いくつかの問題がある

  - 回帰式の定式化に強く依存する
  
  - 一般に平均効果ではなく、加重平均が推計される
  
  - サンプルサイズに比べて、少数のコントロール変数を導入できない

- 以下ではマッチング法、機械学手法を用いた頑強な推定を目指す

### 発展:推計結果表{-}

- tidy関数により推定結果data.frameに変化することで、kable関数(knitrパッケージ)による推計結果表の整形、geom_pointrange関数による可視化が可能

- 点推定値(estimate)、標準誤差(std.error)のみを残した推計結果表

```{r}
library(knitr)

fit <- 
  lm_robust(visits ~ insurance + region + age + afam + gender + school,
            data = raw)

fit <- tidy(fit)

fit <- select(fit, term, estimate, std.error)

kable(fit, digits = 2)
```

```{r}
fit <- filter(fit,
              term == "insuranceyes")

kable(fit, digits = 2)
```


### 発展:Dot-and-Whisker plotによる可視化{-}

- Dot-and-Whisker図により点推定量と信頼区間を可視化

```{r}
fit <- 
  lm_robust(visits ~ insurance + region + age + afam + gender + school,
            data = raw)

fit <- tidy(fit)

fit <- filter(fit,
              term != "(Intercept)")

ggplot(fit, aes(y = term,
                x = estimate,
                xmin = conf.low,
                xmax = conf.high)) +
  geom_pointrange()
```


```{r}
fit <- filter(fit,
              term == "insuranceyes")

ggplot(fit, aes(y = term,
                x = estimate,
                xmin = conf.low,
                xmax = conf.high)) +
  geom_pointrange() +
  geom_vline(xintercept = 0)
```

## マッチング法による修正

- 回帰を行う事前準備としてマッチング法を利用する

  - 重回帰が持つ関数形への依存度を減らせる [@ho2007matching]
  
  - MathItパッケージ [@MatchIt2011]を利用

```{r}
library(MatchIt)
```

- 多数のマッチング法が実装されている

### Nearest neighbor matching

```{r}
fit.m <- matchit(insurance ~ region + age + afam + gender + school,
                 data = raw,
                 method = "nearest",
                 estimand = "ATC"
                 )
```

- マッチング結果

```{r}
sum.m <- summary(fit.m)

sum.m
```


- マッチング結果の図示

```{r}
plot(sum.m, xlim=c(0,2))
```

- マッチングしたデータを用いた推定

  - 新たに作成されるweight (defaltではweights)を用いた、加重推定で実装
  
  - replacement無しの場合ｍマッチングしたペア(subclass)でクラスタリングしたrobust standard errorの利用を推奨 [@abadie2021robust]

```{r}
df <- match.data(fit.m) # マッチング結果を含んだ

lm_robust(visits ~ insurance + region + age + afam + gender + school,
          df,
          clusters = subclass,
          weights = weights)
```


### Coarsened exact matching

- Coarsened exact matching[@iacus2012causal]の実装

```{r}
fit.m <- matchit(insurance ~ region + age + afam + gender + school,
                 data = raw,
                 method = "cem",
                 k2k = TRUE,
                 estimand = "ATC")
```

- マッチング結果

```{r}
sum.m <- summary(fit.m)

sum.m
```


- 可視化

```{r}
plot(sum.m, xlim=c(0,2))
```

- 推定

```{r}
df <- match.data(fit.m)

lm_robust(visits ~ insurance + region + age + afam + gender + school,
          df,
          clusters = subclass,
          weights = weights)
```

## 部分推計モデルの推定

- 部分線形モデルをロビンソン変換[@robinson1988root]

$$Y_i-\underbrace{E[Y_i|X_i]}_{Nuisance\ term}=\tau\times [D_i-\underbrace{E[D_i|X_i]}_{Nuisance\ term}]+u_i$$

- $E[Y_i|X_i],E[D_i|X_i]$を予測関数として推定し、予測誤差間を単回帰すればよい

- 実際には$E[Y_i|X_i],E[D_i|X_i]$は未知の関数なので何らかの方法で推定する必要がある。関数の推定なので予測の手法が適用できる。

#### Double selection: rlassoEffect (hdm)

- 2重選択法[@belloni2014inference]を紹介

- LASSOにより$Y_i,D_i$の両方あるいはどちらか一方を予測する上でrelevantな$X^c$を特定しコントロールする

  - $Y_i,D_i$どちらの予測にもrelevantではない変数は除外する

- hdmパッケージ[@R-hdm]を利用

```{r}
library(hdm)

Y <- raw$visits

D <- if_else(raw$insurance == "yes",1,0)

X <- model.matrix(~ - 1+ region + age + afam + gender + school + 
                    I(age^2) + I(school^2) +
                    region:age + region:afam + region:gender + region:school +
                    age:afam + age:gender + age:school +
                    afam:gender + afam:school +
                    gender:school,
                  raw)

fit <-
  rlassoEffect(x = X,
               y = Y,
               d = D,
               method = "double selection")
```


- 推定結果

```{r}
summary(fit)
```

- 選択されたコントロール変数

```{r}
fit$selection.index
```


#### Double Machine Learning (DoubleML)

- Double Machine Learning法[@chernozhukov2018double]を紹介

- なんらかの方法（例、OLS、ランダムフォレスト、LASSO）で$E[Y|X],E[D|X]$の予測関数$f_Y(X),f_D(X)$を推定し、予測誤差を単回帰

- DoubleMLパッケージ[@R-DoubleML]を利用

```{r}
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)


X <- model.matrix(~ - 1+ region + age + afam + gender + school,
                  raw)


learner <- 
  lrn("regr.ranger", 
      num.trees = 100) # Require bigger num.trees in practice

ml_g <- learner$clone()

ml_m <- learner$clone()

obj_dml_data <- 
  double_ml_data_from_matrix(X = X,
                             y = as.numeric(Y),
                             d = as.numeric(D))

dml_plr_obj <- 
  DoubleMLPLR$new(obj_dml_data, 
                  ml_g, 
                  ml_m, 
                  dml_procedure="dml1", 
                  n_rep = 3)

dml_plr_obj$fit()
```

```{r}
print(dml_plr_obj)
```
